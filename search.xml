<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>NLP之词向量</title>
    <url>/p/ca8e.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>Word2Vec</tag>
      </tags>
  </entry>
  <entry>
    <title>OCR数据生成之SynthText场景文本</title>
    <url>/p/5c8c.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>OCR</tag>
        <tag>Data Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>深度强化学习DRL从入门到放弃</title>
    <url>/p/32f0.html</url>
    <content><![CDATA[<p><strong><code>Emphasis</code></strong>: 以下内容全是通过个人理解整理所得，如有错误，欢迎指出。<br>**<em>版权所有：杨苏辉**</em></p>
<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><p>本章主要从Reinforcement learning(RL)基本概念出发，介绍传统强化学习的一些经典算法并辅以公式推导和程序实现。</p>
<p><a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/">预习</a></p>
<h2 id="RL基本概念"><a href="#RL基本概念" class="headerlink" title="RL基本概念"></a>RL基本概念</h2><p>在经典强化学习中，智能体要和环境完成一系列交互:<br></p>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930091708.png width="300" height='300' alt='RL基本模型'/></div>
（1）在每一个时刻，系统都将处于一种状态   
（2）智能体将设法得到环境当前状态的观察值    
（3）智能体根据观察值，结合自己历史的行为准则（策略，Policy）做出行动<br>
（4）这个行动会影响环境的状态，是环境发生一定的改变。Agent将从改变后的环境中得到两部分信息：新的环境观测值和行为给出的回报。Agent可以根据新的观测值做出新的行动。<br>

<h3 id="DRL-vs-DL"><a href="#DRL-vs-DL" class="headerlink" title="DRL vs DL"></a>DRL vs DL</h3><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195704.png" alt="image-20191125152833795"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195705.png" alt="image-20191125153004826"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195706.png" alt="image-20191125153318152"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195707.png" alt="image-20191125153351057"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195708.png" alt="image-20191125153424249"></p>
<h3 id="DRL项目搭建流程-PIPELINE"><a href="#DRL项目搭建流程-PIPELINE" class="headerlink" title="DRL项目搭建流程(PIPELINE)"></a>DRL项目搭建流程(PIPELINE)</h3><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195709.png" alt="image-20191125154213166"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195710.png" alt="image-20191125154322290"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195711.png" alt="image-20191125154350506"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195712.png" alt="image-20191125154421405"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195713.png" alt="image-20191125154504303"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195714.png" alt="image-20191125154530205"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195715.png" alt="image-20191125154611740"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195716.png" alt="image-20191125154642408"></p>
<h3 id="DRL-examples"><a href="#DRL-examples" class="headerlink" title="DRL examples"></a>DRL examples</h3><p><a href="https://gym.openai.com/docs/">Gym-Cart-Pole</a></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930092157.JPG"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930092247.JPG" alt="42"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930092320.JPG" alt="43"></p>
<p><strong>更多应用场景：</strong></p>
<p>自动驾驶: 自动驾驶载具（self-driving vehicle）<br>控制论(离散和连续大动作空间): 玩具直升机、Gymm_cotrol物理部件控制、机器人行走、机械臂控制。<br>游戏: Go, Atari 2600(DeepMind论文详解)等<br>理解机器学习: 自然语言识别和处理, 文本序列预测<br>超参数学习: 神经网络参数自动设计<br>问答系统: 对话系统<br>推荐系统: 阿里巴巴黄皮书（商品推荐），广告投放。<br>智能电网: 电网负荷调试, 调度等<br>通信网络: 动态路由, 流量分配等<br>物理化学实验: 定量实验,核素碰撞,粒子束流调试等<br>程序学习和网络安全: 网络攻防等</p>
<p><strong>第一课作业：</strong></p>
<p>下图中根据每个人自己的理解对human life进行抽象，得到Goal、State、Actions、Reward指标。</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930092721.JPG" alt="44"></p>
<h3 id="keypoints"><a href="#keypoints" class="headerlink" title="keypoints"></a>keypoints</h3><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930092852.JPG" alt="39"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195717.png" alt="image-20191125154932764"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930092935.JPG" alt="40"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195718.png" alt="image-20191125154831799"></p>
<h3 id="简化模型及MDP"><a href="#简化模型及MDP" class="headerlink" title="简化模型及MDP"></a>简化模型及MDP</h3><h4 id="RL模型简化"><a href="#RL模型简化" class="headerlink" title="RL模型简化"></a>RL模型简化</h4><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195719.png" alt="image-20191125154722065"></p>
   <div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093009.png width="450" height='200' alt='RL简化模型'/></div><br>

<p>来自Sutton和Barto的书“Reinforcement Learning: an Introduction”（这是强烈推荐的）的这张图，很好的解释了智能体和环境之间的相互作用。在某个时间步t，智能体处于状态s_t，采取动作a_t。然后环境会返回一个新的状态s_t+1和一个奖励r_t+1。奖励处于t+1时间步是因为它是由环境在t+1的状态s_t+1返回的，因此让它们两个保持一致更加合理（如上图所示）。</p>
<h4 id="MDP模型"><a href="#MDP模型" class="headerlink" title="MDP模型"></a>MDP模型</h4><div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093228.png width="600" height='200' alt='MDP简化模型'/></div><br>

<p>你不需要一个MDP来告诉自己饿了要吃饭，但是强化学习的机制是需要它的。这个MDP增加了奖励机制，你每转化到一个状态，就会获得一次奖励。在这个例子中，由于接下来状态是饥饿，你会得到一个负面的奖励，如果接下来状态是饿死，那会得到一个更负面的奖励。如果你吃饱了，就会获得一个正面的奖励。现在我们的MDP已经完全成型，我们可以开始思考如何采取行动去获取能获得的最高奖励。由于这个MDP是十分简单的，我们很容易发现待在一个更高奖励的区域的方式，即当我们饥饿的时候就吃。在这个模型中，当我们处于吃饱状态的时候没有太多其它的选择，但是我们将会不可避免的再次饥饿，然后立马选择进食。强化学习感兴趣的问题其实具有更大更复杂的马尔科夫决策过程，并且在我们开始实际探索前，我们通常不知道这些策略。</p>
<p>百度百科对马尔可夫链和决策过程的解释：</p>
<p><a href="%5Bhttps://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE/6171383%5D(https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE/6171383)">马尔可夫链</a></p>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093539.JPG width="600" height='400' alt='MDP简化模型'/></div><br>

<p><a href="%5Bhttps://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/5824810?fr=aladdin%5D(https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/5824810?fr=aladdin)">马尔可夫决策过程</a></p>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093640.JPG width="600" height='400' alt='MDP简化模型'/></div><br>

<p><strong>举个例子，一个抛物线小球，给出当前时刻的速度和位置(当前时刻的状态)，下一时刻的小球位置只取觉与当前时刻的小球状态；但是如果只给出当前时刻小球的位置，则下一时刻小球的位置取决于之前所有时刻小球的状态，这时候不具有马尔可夫性质。</strong></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195720.png" alt="image-20191125155054862"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195721.png" alt="image-20191125155145767"></p>
<p>我们现在已经有一个强化学习问题的框架，接下来准备学习如何最大化奖励函数。在下一部分中，我们将进一步学习状态价值（state value）函数和状态-动作价值（action value）函数，以及奠定了强化学习算法基础的贝尔曼（Bellman）方程，并进一步探索一些简单而有效的动态规划解决方案。</p>
<h3 id="Bellman-Equation优化"><a href="#Bellman-Equation优化" class="headerlink" title="Bellman Equation优化"></a>Bellman Equation优化</h3><p>推导方式一：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093727.jpg" alt="20"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093747.jpg" alt="21"></p>
<p>推导方式二：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930093834.JPG" alt="52"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094024.png" alt="s5"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094043.JPG" alt="51"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094103.JPG" alt="53"></p>
<p><strong>同一个状态state下同一策略输出的动作不一定是确定的，(例如石头剪刀布中最优策略是随机策略)，因此在Bellman Equation推导过程中一定注意每一个变量自身又是一个随机变量；同时即使在同一个状态state下根据一个最优的确定性策略输出确定性动作，得到的下一个state也不一定是唯一确定的，这里会有一个状态转移概率(因此在这里会有确定性环境和不确定环境之分，不确定环境就是同一s，a下一个s不确定)。</strong></p>
<p><strong><u>臆想场景：</u></strong></p>
<p>策略是一个战略方针，不是具体的战术动作，例如”敌进我退敌驻我扰敌疲我打敌退我追”16字方针就是一个策略，具体的战术动作需要根据当前所处的状态决定；</p>
<p>1、行军打战到某处，例如灌木从，此时可以有前哨兵勘测地形和敌军状态，例如离我军多远，装备如何，人数，是否是王牌部队等等，继而根据16字方针决定接下来我军的作战策略，是打，是跑还是什么，这个16字方针就可以看作是与敌军不断流血斗争中学到的最优策略；</p>
<p>2、同一个时间，同一个地点，男生向女生表白，得到的下一个状态可能是被拒绝也有可能是接受；即同一个s，a，下一个状态不一定是确定的；</p>
<p>3、石头剪刀布中面对对方出布，我方最优策略是随机策略，即三个动作概率是一样的，不然随着游戏的进行，有所偏重的动作就会被针对，一定是很多局；</p>
<p>4、on-off policy例子，为什么比你高，壮的人，本能是不与之打架，这就是off policy，自己的不打的动作来源于其他人的policy，即其他人打架的与环境的交互行为(结果被暴揍)和自身更新policy不是一个policy；on-policy就是自己不信邪，非要以身尝试，不停的打架最后发现打不过不打了。</p>
<h3 id="算法归纳"><a href="#算法归纳" class="headerlink" title="算法归纳"></a>算法归纳</h3> <div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094136.png width="600" height='400' alt='RL简化模型'/></div><br>

<h2 id="Model-based-models"><a href="#Model-based-models" class="headerlink" title="Model-based models"></a>Model-based models</h2><p>基于model的方法是指环境信息可以获取，例如环境状态转移概率等信息，与之对应的是model-free的方法，该类方法无法获取环境的准确信息，例如无法直接获取环境的状态转移概率；</p>
<p> 对于贝尔曼方程的求解，可以采取动态规划（Dynamic Programming）的方法。具体来说，动态规划有两个方法： 这里主要介绍两个model-based的方法，包括值迭代和策略迭代方法。</p>
<h3 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h3><p> 算法主要流程如下：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094237.JPG" alt="22"></p>
<p><a href="https://blog.csdn.net/hhy_csdn/article/details/89091008">示例代码</a></p>
<p>环境：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094304.JPG" alt="25"></p>
<p>值迭代函数：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094336.JPG" alt="23"></p>
<p>策略policy获取：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094403.JPG" alt="24"></p>
<h3 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration"></a>Policy Iteration</h3><p>算法主要流程如下：</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094434.JPG" alt="26"></p>
<p><a href="https://blog.csdn.net/hhy_csdn/article/details/89096938">示例代码</a></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094457.JPG" alt="27"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094512.JPG" alt="28"></p>
<p><strong>不管是值迭代还是策略迭代，都是需要计算出最优的值函数，然后通过值函数计算出Q函数，然后根据Q函数计算出每个状态state下的最优动作action。</strong></p>
<h2 id="Model-free-models"><a href="#Model-free-models" class="headerlink" title="Model-free models"></a>Model-free models</h2><p>很多情况下，环境的模型是未知的，我们不清楚状态之间如何转移，回报的概率是多少，甚至不清楚全部的状态空间长什么样子。这种情况下，如果不采用model-based方法（即，对复杂环境进行建模，建模过程其实就是学习过程，模型建的充分了，智能体对环境就理解充分了，就可以得出最优policy），而是采用model-free的方法（不去对环境进行建模，只用采样的方式学习出一个最优policy），最经典的就是<a href="https://blog.csdn.net/hhy_csdn/article/details/89156891">蒙特卡罗算法</a>了。</p>
<h3 id="Monte-Carlo-MC-Methods"><a href="#Monte-Carlo-MC-Methods" class="headerlink" title="Monte Carlo(MC) Methods"></a>Monte Carlo(MC) Methods</h3><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094541.JPG" alt="29"></p>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094633.JPG width="300" height='300' alt='RL简化模型'/></div><br>

<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094751.JPG" alt="31"></p>
<h3 id="Temporal-Difference-TD-lambda-Methods"><a href="#Temporal-Difference-TD-lambda-Methods" class="headerlink" title="Temporal Difference(TD(lambda)) Methods"></a>Temporal Difference(TD(lambda)) Methods</h3><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094847.JPG" alt="32"></p>
<p>时间差分(TD)方法主要包括Q-learning和SARSA方法，其中根据Q值更新受影响的步长lambda，有Q-learning(lambda)和SARSA(lambda)。</p>
<p><strong>注意：这里的Q-learning是off-policy算法，SARSA是on-policy算法。</strong></p>
<h4 id="Q-learning-methods"><a href="#Q-learning-methods" class="headerlink" title="Q-learning methods"></a>Q-learning methods</h4><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094915.JPG" alt="33"></p>
<p><a href="https://blog.csdn.net/hhy_csdn/article/details/89157318">代码</a></p>
<h4 id="SARSA-methods"><a href="#SARSA-methods" class="headerlink" title="SARSA methods"></a>SARSA methods</h4><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930094945.JPG" alt="34"></p>
<p><a href="https://blog.csdn.net/hhy_csdn/article/details/89216872">代码</a></p>
<h5 id="超参数分析"><a href="#超参数分析" class="headerlink" title="超参数分析"></a>超参数分析</h5><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095016.JPG" alt="35"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095031.JPG" alt="36"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195722.png" alt="image-20191125190408199"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195723.png" alt="image-20191125190544026"></p>
<h4 id="Q-learning-SARSA-lambda-methods"><a href="#Q-learning-SARSA-lambda-methods" class="headerlink" title="Q-learning/SARSA(lambda) methods"></a>Q-learning/SARSA(lambda) methods</h4><div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095059.JPG width="1000" height='500' alt='RL简化模型'/></div><br>

<p>Sarsa 是说到做到型, 所以我们也叫他 on-policy, 在线学习, 学着自己在做的事情.Sarsa相当保守,他会选择离危险远远的,拿到宝藏是次要的, 保住自己的小命才是王道. 这就是使用 Sarsa 方法的不同之处.<br>Q learning 是说到但并不一定做到,所以它也叫作 Off-policy,离线学习.而因为有了 maxQ,Q-learning 也是一个特别勇敢的算法.永远都会选择最近的一条通往成功的道路, 不管这条路会有多危险.</p>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095152.JPG width="1000" height='400' alt='RL简化模型'/></div><br>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095220.JPG width="1000" height='400' alt='RL简化模型'/></div><br>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095249.JPG width="1000" height='300' alt='RL简化模型'/></div><br>
<div align=center><img data-src=https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095319.JPG width="1000" height='300' alt='RL简化模型'/></div><br>

<p><strong>注意lambda是0时，是单步更新，lambda是1时，是回合更新，lambda在0-1之间时，是成一个衰减趋势，离更新近的权重大，远的步权重小。</strong></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095350.png" alt="s3"></p>
<p>DP、MC、TD三种方法对比：<br>1、DP基于模型; MC、TD基于无模型<br>2、DP采用bootstrapping(自举), MC采用采样，TD采用bootstrapping+采样<br>3、DP用后继状态的值函数估计当前值函数，MC利用经验平均估计状态的值函数，TD利用后继状态的值函数估计当前值函数<br>4、MC和TD都是利用样本估计值函数，其中MC为无偏估计，TD为有偏估计<br>5、最明显的就是下图的值函数的计算方法的不同</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095416.JPG" alt="40"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200928195724.png"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095445.png" alt="s1"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095459.png" alt="s4"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095515.JPG" alt="57"></p>
<p><a href="https://www.jianshu.com/p/40aff6fad7b9">特点：</a></p>
<p>  （1）不断试错<br>  （2）看重长期回报 </p>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1、<a href="https://blog.csdn.net/qq_30615903/article/details/80746553"> https://blog.csdn.net/qq_30615903/article/details/80746553 </a></p>
<p>2、<a href="https://www.lizenghai.com/archives/20955.html"> https://www.lizenghai.com/archives/20955.html </a></p>
<p>3、Reinforcement learning：An Introduction</p>
<p>4、<a href="https://www.bilibili.com/video/av16921335/#page=22">视频课程</a></p>
<p>5、…………待添加</p>
<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><p>本章主要从Deep Reinforcement learning(DRL)基本概念出发，介绍深度强化学习的一些经典算法并辅以公式推导和程序实现。</p>
<h2 id="DRL基本概念"><a href="#DRL基本概念" class="headerlink" title="DRL基本概念"></a>DRL基本概念</h2><p>传统的强化学习局限于动作空间和样本空间都很小，且一般是离散的情境下。然而比较复杂的、更加接近实际情况的任务则往往有着很大的状态空间和连续的动作空间。当输入数据为图像，声音时，往往具有很高维度，传统的强化学习很难处理，深度强化学习就是把深度学习对于的高维输入与强化学习结合起来。 </p>
<h2 id="DRL-经典算法"><a href="#DRL-经典算法" class="headerlink" title="DRL 经典算法"></a>DRL 经典算法</h2><p> 2013和2015年DeepMind的Deep Q Network（DQN）可谓是将两者成功结合的开端，它用一个深度网络代表价值函数，依据强化学习中的Q-Learning，为深度网络提供目标值，对网络不断更新直至收敛， 后续还有很多基于DQN的改进版本。<strong>但是DQN主要用于解决离散动作空间的问题，无法解决高维连续动作空间，而PG不仅可以用于解决高维连续动作空间，也可以解决离散动作空间问题。同时将PG和值函数两者的优势相结合得到的Actor-Critic框架系列方法性能得到进一步提升。</strong>  </p>
<p><strong>DDPG可以学习随机策略和连续动作，原始的DQN则无法学习随机策略和连续动作。</strong></p>
<p><strong>随机策略(非确定性策略)vs确定性策略</strong></p>
<p> 那么什么是策略呢？ 通常情况下被定义为是从状态到行为的一个映射，<strong>直白说就是每个状态下指定一个动作概率，这个可以是确定性的（一个确定动作），也可以是不确定性的。</strong> </p>
<p>策略是一个战略方针，不是具体的战术动作，例如”敌进我退敌驻我扰敌疲我打敌退我追”就是一个策略，具体的战术动作需要根据当前所处的状态决定；</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095551.JPG" alt="50"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095608.JPG" alt="54"></p>
<p><strong>离散动作vs连续动作</strong></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095630.JPG" alt="55"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930095643.JPG" alt="56"></p>
<h3 id="DRL-Model-free-Methods"><a href="#DRL-Model-free-Methods" class="headerlink" title="DRL Model-free Methods"></a>DRL Model-free Methods</h3><p>下面介绍的DQN系列算法、DDPG系列算法和AC系列算法属于model-free的范畴，即不需要对环境建模，主要通过与环境交互获取抽样样本进行模型的训练。</p>
<h4 id="Deep-Q-learning-Network-DQN"><a href="#Deep-Q-learning-Network-DQN" class="headerlink" title="Deep Q-learning Network(DQN)"></a>Deep Q-learning Network(DQN)</h4><p>下图直观展示DQN算法训练后的吃豆豆的游戏agent。</p>
<div align=center><img data-src=https://raw.githubusercontent.com/yangsuhui/PicGoPictureBed/master/img/20200930103954.gif width="400" height='400' alt='RL简化模型'/></div><br>

<p>作为深度强化学习领域的重要开创性工作，DQN的出现引发了众多研究团队的关注。在文献[1]中，介绍了DQN早期的主要改进工作，包括大规模分布式DQN[14]、双重DQN[15]、带优先级经验回放的DQN[16]、竞争架构DQN[17]、引导DQN[18]以及异步DQN[19]等。这些工作从不同角度改进DQN的性能。</p>
<p>此后，研究人员又陆续提出了一些DQN的重要扩展，继续完善DQN算法。Zhao等基于在策略(on-policy)强化学习，提出了深度SARSA(state-action-reward-state-action)算法[20]。实验证明在一些Atari视频游戏上，深度SARSA算法的性能要优于DQN。Anschel等提出了平均DQN，通过取Q值的期望以降低目标值函数的方差，改善了深度强化学习算法的不稳定性[21]。实验结果表明，平均DQN在ALE测试平台上的效果要优于DQN和双重DQN。He等在DQN的基础上提出一种约束优化算法来保证策略最优和奖赏信号快速传播[22]。该算法极大提高了DQN的训练速度，在ALE平台上经过一天训练就达到了DQN和双重DQN经过十天训练的效果。作为DQN的一种变体，分类DQN算法从分布式的角度分析深度强化学习[23]。与传统深度强化学习算法中选取累积奖赏的期望不同，分类DQN将奖赏看作一个近似分布，并且使用贝尔曼等式学习这个近似分布。分类DQN算法在Atari视频游戏上的平均表现要优于大部分基准算法。深度强化学习中参数的噪声可以帮助算法更有效地探索周围的环境，加入参数噪声的训练算法可以大幅提升模型的效果，并且能更快地教会智能体执行任务。噪声DQN在动作空间中借助噪声注入进行探索性行为，结果表明带有参数噪声的深度强化学习将比分别带有动作空间参数和进化策略的传统强化学习效率更高[24]。彩虹(Rainbow)将各类DQN的算法优势集成在一体，取得目前最优的算法性能，视为DQN算法的集大成者[25]。DQN算法及其主要扩展如下图所示：</p>
<p><img data-src="https://raw.githubusercontent.com/yangsuhui/PicGoPictureBed/master/img/20200930125500.jpg" alt="s10"></p>
<h5 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h5><h5 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h5><h5 id="Prioritised-replay"><a href="#Prioritised-replay" class="headerlink" title="Prioritised replay"></a>Prioritised replay</h5><h5 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h5><h5 id="RainBow"><a href="#RainBow" class="headerlink" title="RainBow"></a>RainBow</h5><h4 id="Deep-Deterministic-Policy-Gradient-DDPG"><a href="#Deep-Deterministic-Policy-Gradient-DDPG" class="headerlink" title="Deep Deterministic Policy Gradient(DDPG)"></a>Deep Deterministic Policy Gradient(DDPG)</h4><p><strong>基于值函数的深度强化学习主要应用于离散动作空间的任务。面对连续动作空间的任务，基于策略梯度的深度强化学习算法能获得更好的决策效果。</strong> </p>
<p>==分类：在策略/离策略梯度；随机/确定性策略梯度；==</p>
<p>目前<strong>的大部分actor-critic算法都是采用在策略的强化学习算法。这意味着无论使用何种策略进行学习，critic部分都需要根据当前actor的输出作用于环境产生的反馈信号才能学习</strong>。因此，<strong>在策略类型</strong>的actor-critic算法是<strong>无法使用类似于经验回放的技术提升学习效率的，也由此带来训练的不稳定和难以收敛性</strong>。Lillicrap等提出的<strong>深度确定性策略梯度算法(deep deterministic policy gradient，DDPG)，将DQN算法在离散控制任务上的成功经验应用到连续控制任务的研究[30]。DDPG是无模型、离策略(offpolicy)的actor-critic算法</strong>，使用深度神经网络作为逼近器，将**深度学习和确定性策略梯度算法有效地结合在一起。DDPG源于确定性策略梯度(determinist policy gradient，DPG)算法[31]**。确定性策略记为πθ(s)，表示状态S和动作A在参数θ的策略作用下得到S7→A。期望奖赏J(π)如下所示:</p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125658.JPG" alt="58"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125725.JPG" alt="59"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125741.JPG" alt="60"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125758.JPG" alt="61"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125817.JPG" alt="62"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125832.png" alt="s7"></p>
<h5 id="Policy-gradient"><a href="#Policy-gradient" class="headerlink" title="Policy gradient"></a>Policy gradient</h5><h5 id="Stochastic-policy-gradient-SPG-vs-determinist-policy-gradient-DPG"><a href="#Stochastic-policy-gradient-SPG-vs-determinist-policy-gradient-DPG" class="headerlink" title="Stochastic policy gradient (SPG)  vs  determinist policy gradient (DPG)"></a>Stochastic policy gradient (SPG)  vs  determinist policy gradient (DPG)</h5><h5 id="DDPG"><a href="#DDPG" class="headerlink" title="DDPG"></a>DDPG</h5><h5 id="Trust-region-policy-optimization-TRPO"><a href="#Trust-region-policy-optimization-TRPO" class="headerlink" title="Trust region policy optimization (TRPO)"></a>Trust region policy optimization (TRPO)</h5><h5 id="PPO"><a href="#PPO" class="headerlink" title="PPO"></a>PPO</h5><h4 id="Actor-Critic-Series-Method-AC"><a href="#Actor-Critic-Series-Method-AC" class="headerlink" title="Actor Critic Series Method(AC)"></a>Actor Critic Series Method(AC)</h4><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125918.png" alt="s6"></p>
<h5 id="AC"><a href="#AC" class="headerlink" title="AC"></a>AC</h5><h5 id="A2C"><a href="#A2C" class="headerlink" title="A2C"></a>A2C</h5><h5 id="A3C"><a href="#A3C" class="headerlink" title="A3C"></a>A3C</h5><h5 id="UNREAL"><a href="#UNREAL" class="headerlink" title="UNREAL"></a>UNREAL</h5><h3 id="DRL-Model-based-Methods"><a href="#DRL-Model-based-Methods" class="headerlink" title="DRL Model-based Methods"></a>DRL Model-based Methods</h3><h4 id="World-Model"><a href="#World-Model" class="headerlink" title="World Model"></a>World Model</h4><h4 id="PlaNet"><a href="#PlaNet" class="headerlink" title="PlaNet"></a>PlaNet</h4><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930125951.png" alt="s8"></p>
<p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930130009.png" alt="s1"></p>
<h2 id="QA-1"><a href="#QA-1" class="headerlink" title="QA"></a>QA</h2><h2 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h2><h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="Environmental-interaction-framework"><a href="#Environmental-interaction-framework" class="headerlink" title="Environmental interaction framework"></a>Environmental interaction framework</h2><p>gym只支持linux，Tkinter可以支持win/linux</p>
<h3 id="OpenAI-gym"><a href="#OpenAI-gym" class="headerlink" title="OpenAI gym"></a><a href="https://github.com/openai/gym">OpenAI gym</a></h3><h3 id="Tkinter-可学-你可以自己用它来编写模拟环境"><a href="#Tkinter-可学-你可以自己用它来编写模拟环境" class="headerlink" title="Tkinter (可学), 你可以自己用它来编写模拟环境"></a><a href="https://morvanzhou.github.io/tutorials/python-basic/tkinter/">Tkinter</a> (可学), 你可以自己用它来编写模拟环境</h3><h2 id="AlphaGo-Series"><a href="#AlphaGo-Series" class="headerlink" title="AlphaGo Series"></a>AlphaGo Series</h2><p><img data-src="https://gitee.com/yangsuhui_i/pic-go-picture-bed/raw/master/imgs/deep_RL/20200930130047.png" alt="s9"></p>
<h3 id="AlphaGo"><a href="#AlphaGo" class="headerlink" title="AlphaGo"></a>AlphaGo</h3><h3 id="AlphaGo-Master"><a href="#AlphaGo-Master" class="headerlink" title="AlphaGo Master"></a>AlphaGo Master</h3><h3 id="AlphaGo-Zero"><a href="#AlphaGo-Zero" class="headerlink" title="AlphaGo Zero"></a>AlphaGo Zero</h3><h3 id="AlphaZero"><a href="#AlphaZero" class="headerlink" title="AlphaZero"></a>AlphaZero</h3><h3 id="MuZero"><a href="#MuZero" class="headerlink" title="MuZero"></a>MuZero</h3><h2 id="DRL的主要研究方向"><a href="#DRL的主要研究方向" class="headerlink" title="DRL的主要研究方向"></a>DRL的主要研究方向</h2><h3 id="科学研究方向"><a href="#科学研究方向" class="headerlink" title="科学研究方向"></a>科学研究方向</h3><h4 id="Reward-Shaping"><a href="#Reward-Shaping" class="headerlink" title="Reward Shaping"></a>Reward Shaping</h4><h4 id="Multi-Agent-DRL"><a href="#Multi-Agent-DRL" class="headerlink" title="Multi-Agent DRL"></a>Multi-Agent DRL</h4><h5 id="MADDPG"><a href="#MADDPG" class="headerlink" title="MADDPG"></a>MADDPG</h5><h4 id="带有迁移属性的强化学习"><a href="#带有迁移属性的强化学习" class="headerlink" title="带有迁移属性的强化学习"></a>带有迁移属性的强化学习</h4><h4 id="元强化学习"><a href="#元强化学习" class="headerlink" title="元强化学习"></a>元强化学习</h4><h4 id="分层强化学习"><a href="#分层强化学习" class="headerlink" title="分层强化学习"></a>分层强化学习</h4><h4 id="强化学习与神经生物学的联系"><a href="#强化学习与神经生物学的联系" class="headerlink" title="强化学习与神经生物学的联系"></a>强化学习与神经生物学的联系</h4><h3 id="应用研究方向"><a href="#应用研究方向" class="headerlink" title="应用研究方向"></a>应用研究方向</h3><h4 id="Recommendation-system-with-DRL"><a href="#Recommendation-system-with-DRL" class="headerlink" title="Recommendation system with DRL"></a>Recommendation system with DRL</h4><h4 id="智能调度-派单-系统"><a href="#智能调度-派单-系统" class="headerlink" title="智能调度(派单)系统"></a>智能调度(派单)系统</h4><h2 id="Competitions"><a href="#Competitions" class="headerlink" title="Competitions"></a>Competitions</h2><h2 id="Other-related-works"><a href="#Other-related-works" class="headerlink" title="Other related works"></a>Other related works</h2><h3 id="进化算法"><a href="#进化算法" class="headerlink" title="进化算法"></a>进化算法</h3><h3 id="蚁群算法"><a href="#蚁群算法" class="headerlink" title="蚁群算法"></a>蚁群算法</h3><h3 id="模拟退火算法"><a href="#模拟退火算法" class="headerlink" title="模拟退火算法"></a>模拟退火算法</h3><h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><h2 id="QA-2"><a href="#QA-2" class="headerlink" title="QA"></a>QA</h2><h2 id="参考资料-2"><a href="#参考资料-2" class="headerlink" title="参考资料"></a>参考资料</h2>]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title>COCOAPI 评价指标解析及功能改进</title>
    <url>/p/5b87.html</url>
    <content><![CDATA[<h1 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h1><p>python eval_coco.py</p>
<h2 id="特别说明"><a href="#特别说明" class="headerlink" title="特别说明"></a>特别说明</h2><p>results_test.json格式如下：</p>
<p>[{“image_id”: 19, “category_id”: 1, “bbox”: [121.4, 116.02, 560.56, 303.83], “score”: 0.97}, {“image_id”: 19, “category_id”: 1, “bbox”: [119.3, 748.22, 566.03, 267.83], “score”: 0.95}, …….<br>{“image_id”: 320, “category_id”: 3, “bbox”: [329.74, 992.53, 35.72, 9.86], “score”: 0.62}]</p>
<p>其中image_id和category_id和instances_test.json中的保持一致，而instances_test.json就是标准的coco格式的gt文件。具体格式如下：</p>
<p>{“licenses”: [{“name”: “”, “id”: 0, “url”: “”}], “info”: {“contributor”: “”, “date_created”: “2020-11-16”, “description”: “table_parse_second_public”, “url”: “”, “version”: 2, “year”: “2020”}, “categories”: [{“id”: 1, “name”: “bordered”, “supercategory”: “”}, {“id”: 2, “name”: “borderless”, “supercategory”: “”}, {“id”: 3, “name”: “cell”, “supercategory”: “”}], “images”: [{“coco_url”: “”, “date_captured”: “”, “flickr_url”: “”, “license”: 0, “id”: 19, “file_name”: “cTDaR_t10019.jpg”, “height”: 1123, “width”: 794}, {“coco_url”: “”, “date_captured”: “”, “flickr_url”: “”, “license”: 0, “id”: 21, “file_name”: “cTDaR_t10021.jpg”, “height”: 1059, “width”: 794}, {“coco_url”: “”, “date_captured”: “”, “flickr_url”: “”, “license”: 0, “id”: 320, “file_name”: “cTDaR_t10507.jpg”, “height”: 1056, “width”: 816}],”annotations”: [{“category_id”: 1, “id”: 1218, “image_id”: 19, “iscrowd”: 0, “segmentation”: [[110.0, 96.0, 683.0, 96.0, 683.0, 437.0, 110.0, 437.0]], “area”: 195393.0, “bbox”: [110.0, 96.0, 573.0, 341.0]}, {“category_id”: 1, “id”: 1219, “image_id”: 19, “iscrowd”: 0, “segmentation”: [[110.0, 732.0, 683.0, 732.0, 683.0, 1025.0, 110.0, 1025.0]], “area”: 167889.0, “bbox”: [110.0, 732.0, 573.0, 293.0]},{“category_id”: 3, “id”: 21911, “image_id”: 320, “iscrowd”: 0, “segmentation”: [[416.0, 845.0, 428.0, 845.0, 428.0, 855.0, 416.0, 855.0]], “area”: 120.0, “bbox”: [416.0, 845.0, 12.0, 10.0]}]}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">##The code of eval_coco.py</span><br><span class="line">import pycocotools.coco as coco</span><br><span class="line">from pycocotools.cocoeval import COCOeval</span><br><span class="line">results &#x3D; r&#39;.&#x2F;results_test.json&#39;  ##模型预测结果</span><br><span class="line">anno &#x3D; r&#39;.&#x2F;instances_test2017.json&#39;  ##ground truth</span><br><span class="line">coco_anno &#x3D; coco.COCO(anno)</span><br><span class="line">coco_dets &#x3D; coco_anno.loadRes(results)</span><br><span class="line">coco_eval &#x3D; COCOeval(coco_anno, coco_dets, &quot;bbox&quot;)</span><br><span class="line">coco_eval.evaluate()</span><br><span class="line">coco_eval.accumulate()</span><br><span class="line">coco_eval.summarize()</span><br><span class="line">coco_eval.get_good_predict_data()</span><br></pre></td></tr></table></figure>

<h1 id="修改后的cocoeval"><a href="#修改后的cocoeval" class="headerlink" title="修改后的cocoeval"></a>修改后的cocoeval</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">__author__ &#x3D; &#39;tsungyi_ysh&#39;</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import datetime</span><br><span class="line">import time</span><br><span class="line">from collections import defaultdict</span><br><span class="line">from . import mask as maskUtils</span><br><span class="line">import copy</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">class COCOeval:</span><br><span class="line">    # Interface for evaluating detection on the Microsoft COCO dataset.</span><br><span class="line">    #</span><br><span class="line">    # The usage for CocoEval is as follows:</span><br><span class="line">    #  cocoGt&#x3D;..., cocoDt&#x3D;...       # load dataset and results</span><br><span class="line">    #  E &#x3D; CocoEval(cocoGt,cocoDt); # initialize CocoEval object</span><br><span class="line">    #  E.params.recThrs &#x3D; ...;      # set parameters as desired</span><br><span class="line">    #  E.evaluate();                # run per image evaluation</span><br><span class="line">    #  E.accumulate();              # accumulate per image results</span><br><span class="line">    #  E.summarize();               # display summary metrics of results</span><br><span class="line">    # For example usage see evalDemo.m and http:&#x2F;&#x2F;mscoco.org&#x2F;.</span><br><span class="line">    #</span><br><span class="line">    # The evaluation parameters are as follows (defaults in brackets):</span><br><span class="line">    #  imgIds     - [all] N img ids to use for evaluation</span><br><span class="line">    #  catIds     - [all] K cat ids to use for evaluation</span><br><span class="line">    #  iouThrs    - [.5:.05:.95] T&#x3D;10 IoU thresholds for evaluation</span><br><span class="line">    #  recThrs    - [0:.01:1] R&#x3D;101 recall thresholds for evaluation</span><br><span class="line">    #  areaRng    - [...] A&#x3D;4 object area ranges for evaluation</span><br><span class="line">    #  maxDets    - [1 10 100] M&#x3D;3 thresholds on max detections per image</span><br><span class="line">    #  iouType    - [&#39;segm&#39;] set iouType to &#39;segm&#39;, &#39;bbox&#39; or &#39;keypoints&#39;</span><br><span class="line">    #  iouType replaced the now DEPRECATED useSegm parameter.</span><br><span class="line">    #  useCats    - [1] if true use category labels for evaluation</span><br><span class="line">    # Note: if useCats&#x3D;0 category labels are ignored as in proposal scoring.</span><br><span class="line">    # Note: multiple areaRngs [Ax2] and maxDets [Mx1] can be specified.</span><br><span class="line">    #</span><br><span class="line">    # evaluate(): evaluates detections on every image and every category and</span><br><span class="line">    # concats the results into the &quot;evalImgs&quot; with fields:</span><br><span class="line">    #  dtIds      - [1xD] id for each of the D detections (dt)</span><br><span class="line">    #  gtIds      - [1xG] id for each of the G ground truths (gt)</span><br><span class="line">    #  dtMatches  - [TxD] matching gt id at each IoU or 0</span><br><span class="line">    #  gtMatches  - [TxG] matching dt id at each IoU or 0</span><br><span class="line">    #  dtScores   - [1xD] confidence of each dt</span><br><span class="line">    #  gtIgnore   - [1xG] ignore flag for each gt</span><br><span class="line">    #  dtIgnore   - [TxD] ignore flag for each dt at each IoU</span><br><span class="line">    #</span><br><span class="line">    # accumulate(): accumulates the per-image, per-category evaluation</span><br><span class="line">    # results in &quot;evalImgs&quot; into the dictionary &quot;eval&quot; with fields:</span><br><span class="line">    #  params     - parameters used for evaluation</span><br><span class="line">    #  date       - date evaluation was performed</span><br><span class="line">    #  counts     - [T,R,K,A,M] parameter dimensions (see above)</span><br><span class="line">    #  precision  - [TxRxKxAxM] precision for every evaluation setting</span><br><span class="line">    #  recall     - [TxKxAxM] max recall for every evaluation setting</span><br><span class="line">    # Note: precision and recall&#x3D;&#x3D;-1 for settings with no gt objects.</span><br><span class="line">    #</span><br><span class="line">    # See also coco, mask, pycocoDemo, pycocoEvalDemo</span><br><span class="line">    #</span><br><span class="line">    # Microsoft COCO Toolbox.      version 2.0</span><br><span class="line">    # Data, paper, and tutorials available at:  http:&#x2F;&#x2F;mscoco.org&#x2F;</span><br><span class="line">    # Code written by Piotr Dollar and Tsung-Yi Lin, 2015.</span><br><span class="line">    # Licensed under the Simplified BSD License [see coco&#x2F;license.txt]</span><br><span class="line">    def __init__(self, cocoGt&#x3D;None, cocoDt&#x3D;None, iouType&#x3D;&#39;segm&#39;):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        Initialize CocoEval using coco APIs for gt and dt</span><br><span class="line">        :param cocoGt: coco object with ground truth annotations</span><br><span class="line">        :param cocoDt: coco object with detection results</span><br><span class="line">        :return: None</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        if not iouType:</span><br><span class="line">            print(&#39;iouType not specified. use default iouType segm&#39;)</span><br><span class="line">        self.cocoGt   &#x3D; cocoGt              # ground truth COCO API</span><br><span class="line">        self.cocoDt   &#x3D; cocoDt              # detections COCO API</span><br><span class="line">        self.evalImgs &#x3D; defaultdict(list)   # per-image per-category evaluation results [KxAxI] elements</span><br><span class="line">        self.eval     &#x3D; &#123;&#125;                  # accumulated evaluation results</span><br><span class="line">        self._gts &#x3D; defaultdict(list)       # gt for evaluation</span><br><span class="line">        self._dts &#x3D; defaultdict(list)       # dt for evaluation</span><br><span class="line">        self.params &#x3D; Params(iouType&#x3D;iouType) # parameters</span><br><span class="line">        self._paramsEval &#x3D; &#123;&#125;               # parameters for evaluation</span><br><span class="line">        self.stats &#x3D; []                     # result summarization</span><br><span class="line">        self.ious &#x3D; &#123;&#125;                      # ious between all gts and dts</span><br><span class="line">        print(&#39;-----&#39;)</span><br><span class="line">        if not cocoGt is None:</span><br><span class="line">            self.params.imgIds &#x3D; sorted(cocoGt.getImgIds())</span><br><span class="line">            self.params.catIds &#x3D; sorted(cocoGt.getCatIds())</span><br><span class="line">            print(&#39;length of self.params.imgIds:&#39;,len(self.params.imgIds))</span><br><span class="line">            print(&#39;self.params.catIds:&#39;,self.params.catIds)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def _prepare(self):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        Prepare ._gts and ._dts for evaluation based on params</span><br><span class="line">        :return: None</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        def _toMask(anns, coco):</span><br><span class="line">            # modify ann[&#39;segmentation&#39;] by reference</span><br><span class="line">            for ann in anns:</span><br><span class="line">                rle &#x3D; coco.annToRLE(ann)</span><br><span class="line">                ann[&#39;segmentation&#39;] &#x3D; rle</span><br><span class="line">        p &#x3D; self.params</span><br><span class="line"></span><br><span class="line">        ##通过查看保存的hk_noline检测的json，gts是单幅图像100个检测框，类别都是1(因为hk_noline只有一个类别)</span><br><span class="line">        ##gt是一幅图像对应的gt框，这里的hk_noline是单类别，所以useCats是0，是1，保存的json内容都是一样的</span><br><span class="line">        ##具体的gts和dts的json格式是一个列表，每一个元素是一个字典，一个字典是一个检测框信息；</span><br><span class="line">        ##进一步测试下多类的情况，不同的useCats效果？？</span><br><span class="line">        if p.useCats:</span><br><span class="line">            gts&#x3D;self.cocoGt.loadAnns(self.cocoGt.getAnnIds(imgIds&#x3D;p.imgIds, catIds&#x3D;p.catIds))</span><br><span class="line">            dts&#x3D;self.cocoDt.loadAnns(self.cocoDt.getAnnIds(imgIds&#x3D;p.imgIds, catIds&#x3D;p.catIds))</span><br><span class="line">            f_gts &#x3D; open(&#39;.&#x2F;tmp1214&#x2F;gts_catid.json&#39;,&#39;w+&#39;)</span><br><span class="line">            json_gt &#x3D; json.dumps(gts)</span><br><span class="line">            f_gts.write(json_gt)</span><br><span class="line">            f_gts.close()</span><br><span class="line"></span><br><span class="line">            f_dts &#x3D; open(&#39;.&#x2F;tmp1214&#x2F;dts_catid.json&#39;,&#39;w+&#39;)</span><br><span class="line">            json_dt &#x3D; json.dumps(dts)</span><br><span class="line">            f_dts.write(json_dt)</span><br><span class="line">            f_dts.close()</span><br><span class="line"></span><br><span class="line">            #print(&#39;gts:&#39;,gts)</span><br><span class="line">            #print(&#39;dts:&#39;,dts)</span><br><span class="line">        else:</span><br><span class="line">            gts&#x3D;self.cocoGt.loadAnns(self.cocoGt.getAnnIds(imgIds&#x3D;p.imgIds))</span><br><span class="line">            dts&#x3D;self.cocoDt.loadAnns(self.cocoDt.getAnnIds(imgIds&#x3D;p.imgIds))</span><br><span class="line"></span><br><span class="line">            f_gts &#x3D; open(&#39;.&#x2F;tmp1214&#x2F;gts_no_catid.json&#39;,&#39;w+&#39;)</span><br><span class="line">            json_gt &#x3D; json.dumps(gts)</span><br><span class="line">            f_gts.write(json_gt)</span><br><span class="line">            f_gts.close()</span><br><span class="line"></span><br><span class="line">            f_dts &#x3D; open(&#39;.&#x2F;tmp1214&#x2F;dts_no_catid.json&#39;,&#39;w+&#39;)</span><br><span class="line">            json_dt &#x3D; json.dumps(dts)</span><br><span class="line">            f_dts.write(json_dt)</span><br><span class="line">            f_dts.close()</span><br><span class="line"></span><br><span class="line">        # convert ground truth to mask if iouType &#x3D;&#x3D; &#39;segm&#39;</span><br><span class="line">        if p.iouType &#x3D;&#x3D; &#39;segm&#39;:</span><br><span class="line">            _toMask(gts, self.cocoGt)</span><br><span class="line">            _toMask(dts, self.cocoDt)</span><br><span class="line">        # set ignore flag</span><br><span class="line">        for gt in gts:</span><br><span class="line">            gt[&#39;ignore&#39;] &#x3D; gt[&#39;ignore&#39;] if &#39;ignore&#39; in gt else 0</span><br><span class="line">            gt[&#39;ignore&#39;] &#x3D; &#39;iscrowd&#39; in gt and gt[&#39;iscrowd&#39;]</span><br><span class="line">            if p.iouType &#x3D;&#x3D; &#39;keypoints&#39;:</span><br><span class="line">                gt[&#39;ignore&#39;] &#x3D; (gt[&#39;num_keypoints&#39;] &#x3D;&#x3D; 0) or gt[&#39;ignore&#39;]</span><br><span class="line">        ##这种声明方式产生的self._gts是一个字典，每个元素是列表</span><br><span class="line">        ##这样得到的就是相同的img_id和类别id的信息，存放在一个列表中，即一张图像的同一个类别的框在一个列表中；</span><br><span class="line">        self._gts &#x3D; defaultdict(list)       # gt for evaluation</span><br><span class="line">        self._dts &#x3D; defaultdict(list)       # dt for evaluation</span><br><span class="line">        ## gts中一个gt格式：&#123;&quot;area&quot;: 735345, &quot;iscrowd&quot;: 0, &quot;image_id&quot;: 20190000781, &quot;bbox&quot;: [225, 1052, 1257, 585], &quot;category_id&quot;: 1, &quot;id&quot;: 1063, &quot;ignore&quot;: 0, &quot;segmentation&quot;: []&#125;</span><br><span class="line">        for gt in gts:</span><br><span class="line">            self._gts[gt[&#39;image_id&#39;], gt[&#39;category_id&#39;]].append(gt)</span><br><span class="line">        ## dts中一个dt格式：&#123;&quot;image_id&quot;: 20190000781, &quot;category_id&quot;: 1, &quot;bbox&quot;: [1584.88, 884.44, 152.43, 308.34], &quot;score&quot;: 0.0, &quot;segmentation&quot;: [[1584.88, 884.44, 1584.88, 1192.78, 1737.3100000000002, 1192.78, 1737.3100000000002, 884.44]], &quot;area&quot;: 47000.2662, &quot;id&quot;: 78100, &quot;iscrowd&quot;: 0&#125;</span><br><span class="line">        for dt in dts:</span><br><span class="line">            self._dts[dt[&#39;image_id&#39;], dt[&#39;category_id&#39;]].append(dt)</span><br><span class="line">        self.evalImgs &#x3D; defaultdict(list)   # per-image per-category evaluation results</span><br><span class="line">        self.eval     &#x3D; &#123;&#125;                  # accumulated evaluation results</span><br><span class="line"></span><br><span class="line">        self.gt_id2img_id &#x3D; &#123;&#125;</span><br><span class="line">        for gt_i in gts:</span><br><span class="line">            self.gt_id2img_id[gt_i[&#39;id&#39;]] &#x3D; gt_i[&#39;image_id&#39;]</span><br><span class="line">        </span><br><span class="line">        self.gt_imgid_cat_id &#x3D; &#123;&#125;</span><br><span class="line">        for gt_i in gts:</span><br><span class="line">            if gt_i[&#39;image_id&#39;] not in self.gt_imgid_cat_id.keys():</span><br><span class="line">                self.gt_imgid_cat_id[gt_i[&#39;image_id&#39;]] &#x3D; &#123;&#125;</span><br><span class="line">                for cat in self.params.catIds:</span><br><span class="line">                    self.gt_imgid_cat_id[gt_i[&#39;image_id&#39;]][cat] &#x3D; []</span><br><span class="line">            self.gt_imgid_cat_id[gt_i[&#39;image_id&#39;]][gt_i[&#39;category_id&#39;]].append(gt_i[&#39;id&#39;])</span><br><span class="line">                #self.gt_imgid_cat_id[gt_i[&#39;image_id&#39;]][gt_i[&#39;category_id&#39;]].append(gt_i[&#39;id&#39;])</span><br><span class="line">                </span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">    def evaluate(self):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        Run per image evaluation on given images and store results (a list of dict) in self.evalImgs</span><br><span class="line">        :return: None</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        tic &#x3D; time.time()</span><br><span class="line">        print(&#39;Running per image evaluation...&#39;)</span><br><span class="line">        p &#x3D; self.params</span><br><span class="line">        # add backward compatibility if useSegm is specified in params</span><br><span class="line">        if not p.useSegm is None:</span><br><span class="line">            p.iouType &#x3D; &#39;segm&#39; if p.useSegm &#x3D;&#x3D; 1 else &#39;bbox&#39;</span><br><span class="line">            print(&#39;useSegm (deprecated) is not None. Running &#123;&#125; evaluation&#39;.format(p.iouType))</span><br><span class="line">        print(&#39;Evaluate annotation type *&#123;&#125;*&#39;.format(p.iouType))</span><br><span class="line">        p.imgIds &#x3D; list(np.unique(p.imgIds))  ##唯一imgid</span><br><span class="line">        if p.useCats:</span><br><span class="line">            p.catIds &#x3D; list(np.unique(p.catIds))  ##唯一gt类别id，不包括背景</span><br><span class="line">        p.maxDets &#x3D; sorted(p.maxDets)</span><br><span class="line">        self.params&#x3D;p</span><br><span class="line"></span><br><span class="line">        self._prepare()</span><br><span class="line">        # loop through images, area range, max detection number</span><br><span class="line">        catIds &#x3D; p.catIds if p.useCats else [-1]</span><br><span class="line"></span><br><span class="line">        if p.iouType &#x3D;&#x3D; &#39;segm&#39; or p.iouType &#x3D;&#x3D; &#39;bbox&#39;:</span><br><span class="line">            computeIoU &#x3D; self.computeIoU</span><br><span class="line">        elif p.iouType &#x3D;&#x3D; &#39;keypoints&#39;:</span><br><span class="line">            computeIoU &#x3D; self.computeOks</span><br><span class="line"></span><br><span class="line">        ##self.ious是一个字典，每一个元素是表示一张图中某一个类别的预测框(m个)和这个类别的gt(n个)的iou矩阵(m,n)</span><br><span class="line">        self.ious &#x3D; &#123;(imgId, catId): computeIoU(imgId, catId) \</span><br><span class="line">                        for imgId in p.imgIds</span><br><span class="line">                        for catId in catIds&#125;</span><br><span class="line"></span><br><span class="line">        evaluateImg &#x3D; self.evaluateImg</span><br><span class="line">        maxDet &#x3D; p.maxDets[-1]</span><br><span class="line">        ##self.evalImgs是列表，每一个元素是字典，存储的是单张图片，一种类别，特定areaRng下的预测框和gt的匹配结果(在不同的阈值下)</span><br><span class="line">        self.evalImgs &#x3D; [evaluateImg(imgId, catId, areaRng, maxDet)</span><br><span class="line">                 for catId in catIds</span><br><span class="line">                 for areaRng in p.areaRng</span><br><span class="line">                 for imgId in p.imgIds</span><br><span class="line">             ]</span><br><span class="line">        self._paramsEval &#x3D; copy.deepcopy(self.params)</span><br><span class="line">        toc &#x3D; time.time()</span><br><span class="line">        print(&#39;DONE (t&#x3D;&#123;:0.2f&#125;s).&#39;.format(toc-tic))</span><br><span class="line"></span><br><span class="line">    def computeIoU(self, imgId, catId):</span><br><span class="line">        p &#x3D; self.params</span><br><span class="line">        if p.useCats:</span><br><span class="line">            gt &#x3D; self._gts[imgId,catId]</span><br><span class="line">            dt &#x3D; self._dts[imgId,catId]</span><br><span class="line">        else:</span><br><span class="line">            gt &#x3D; [_ for cId in p.catIds for _ in self._gts[imgId,cId]]</span><br><span class="line">            dt &#x3D; [_ for cId in p.catIds for _ in self._dts[imgId,cId]]</span><br><span class="line">        if len(gt) &#x3D;&#x3D; 0 and len(dt) &#x3D;&#x3D;0:</span><br><span class="line">            return []</span><br><span class="line">        ##inds是score从大到小排列的索引</span><br><span class="line">        inds &#x3D; np.argsort([-d[&#39;score&#39;] for d in dt], kind&#x3D;&#39;mergesort&#39;)</span><br><span class="line">        ##将此处的dt(一张图片一个类别的所有100个检测框(dt大于100个检测框的，按置信度取前100个(100个由p.maxDets设定))按置信度从大到小排列)</span><br><span class="line">        ##注意是一张图片一种类别的预测框不超过p.maxDets[-1]个，而不是一张图片的预测框不超过这么多，除非设置忽视类别，那就等价于一张图片的总的预测框不多于p.maxDets[-1]</span><br><span class="line">        dt &#x3D; [dt[i] for i in inds]  </span><br><span class="line">        if len(dt) &gt; p.maxDets[-1]:</span><br><span class="line">            dt&#x3D;dt[0:p.maxDets[-1]]</span><br><span class="line"></span><br><span class="line">        if p.iouType &#x3D;&#x3D; &#39;segm&#39;:</span><br><span class="line">            g &#x3D; [g[&#39;segmentation&#39;] for g in gt]</span><br><span class="line">            d &#x3D; [d[&#39;segmentation&#39;] for d in dt]</span><br><span class="line">        elif p.iouType &#x3D;&#x3D; &#39;bbox&#39;:</span><br><span class="line">            g &#x3D; [g[&#39;bbox&#39;] for g in gt]</span><br><span class="line">            d &#x3D; [d[&#39;bbox&#39;] for d in dt]</span><br><span class="line">        else:</span><br><span class="line">            raise Exception(&#39;unknown iouType for iou computation&#39;)</span><br><span class="line">        ##gt和dt是一张图片的一种类别的所有框信息；其中dt中只取p.maxDets[-1]个检测框，按置信度从大到小排序；</span><br><span class="line">        ##g和d是从gt和dt中获取的segmentation信息(分割任务)，检测任务取得是bbox信息；</span><br><span class="line">        # compute iou between each dt and gt region</span><br><span class="line">        iscrowd &#x3D; [int(o[&#39;iscrowd&#39;]) for o in gt]</span><br><span class="line">        ious &#x3D; maskUtils.iou(d,g,iscrowd)   ##ious是(m,n),m是d的个数，即模型的预测检测框个数，n是g的框个数</span><br><span class="line">        return ious</span><br><span class="line"></span><br><span class="line">    def computeOks(self, imgId, catId):</span><br><span class="line">        p &#x3D; self.params</span><br><span class="line">        # dimention here should be Nxm</span><br><span class="line">        gts &#x3D; self._gts[imgId, catId]</span><br><span class="line">        dts &#x3D; self._dts[imgId, catId]</span><br><span class="line">        inds &#x3D; np.argsort([-d[&#39;score&#39;] for d in dts], kind&#x3D;&#39;mergesort&#39;)</span><br><span class="line">        dts &#x3D; [dts[i] for i in inds]</span><br><span class="line">        if len(dts) &gt; p.maxDets[-1]:</span><br><span class="line">            dts &#x3D; dts[0:p.maxDets[-1]]</span><br><span class="line">        # if len(gts) &#x3D;&#x3D; 0 and len(dts) &#x3D;&#x3D; 0:</span><br><span class="line">        if len(gts) &#x3D;&#x3D; 0 or len(dts) &#x3D;&#x3D; 0:</span><br><span class="line">            return []</span><br><span class="line">        ious &#x3D; np.zeros((len(dts), len(gts)))</span><br><span class="line">        sigmas &#x3D; p.kpt_oks_sigmas</span><br><span class="line">        vars &#x3D; (sigmas * 2)**2</span><br><span class="line">        k &#x3D; len(sigmas)</span><br><span class="line">        # compute oks between each detection and ground truth object</span><br><span class="line">        for j, gt in enumerate(gts):</span><br><span class="line">            # create bounds for ignore regions(double the gt bbox)</span><br><span class="line">            g &#x3D; np.array(gt[&#39;keypoints&#39;])</span><br><span class="line">            xg &#x3D; g[0::3]; yg &#x3D; g[1::3]; vg &#x3D; g[2::3]</span><br><span class="line">            k1 &#x3D; np.count_nonzero(vg &gt; 0)</span><br><span class="line">            bb &#x3D; gt[&#39;bbox&#39;]</span><br><span class="line">            x0 &#x3D; bb[0] - bb[2]; x1 &#x3D; bb[0] + bb[2] * 2</span><br><span class="line">            y0 &#x3D; bb[1] - bb[3]; y1 &#x3D; bb[1] + bb[3] * 2</span><br><span class="line">            for i, dt in enumerate(dts):</span><br><span class="line">                d &#x3D; np.array(dt[&#39;keypoints&#39;])</span><br><span class="line">                xd &#x3D; d[0::3]; yd &#x3D; d[1::3]</span><br><span class="line">                if k1&gt;0:</span><br><span class="line">                    # measure the per-keypoint distance if keypoints visible</span><br><span class="line">                    dx &#x3D; xd - xg</span><br><span class="line">                    dy &#x3D; yd - yg</span><br><span class="line">                else:</span><br><span class="line">                    # measure minimum distance to keypoints in (x0,y0) &amp; (x1,y1)</span><br><span class="line">                    z &#x3D; np.zeros((k))</span><br><span class="line">                    dx &#x3D; np.max((z, x0-xd),axis&#x3D;0)+np.max((z, xd-x1),axis&#x3D;0)</span><br><span class="line">                    dy &#x3D; np.max((z, y0-yd),axis&#x3D;0)+np.max((z, yd-y1),axis&#x3D;0)</span><br><span class="line">                e &#x3D; (dx**2 + dy**2) &#x2F; vars &#x2F; (gt[&#39;area&#39;]+np.spacing(1)) &#x2F; 2</span><br><span class="line">                if k1 &gt; 0:</span><br><span class="line">                    e&#x3D;e[vg &gt; 0]</span><br><span class="line">                ious[i, j] &#x3D; np.sum(np.exp(-e)) &#x2F; e.shape[0]</span><br><span class="line">        return ious</span><br><span class="line"></span><br><span class="line">    def evaluateImg(self, imgId, catId, aRng, maxDet):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        perform evaluation for single category and image</span><br><span class="line">        :return: dict (single image results)</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        p &#x3D; self.params</span><br><span class="line">        if p.useCats:</span><br><span class="line">            gt &#x3D; self._gts[imgId,catId]</span><br><span class="line">            dt &#x3D; self._dts[imgId,catId]</span><br><span class="line">        else:</span><br><span class="line">            gt &#x3D; [_ for cId in p.catIds for _ in self._gts[imgId,cId]]</span><br><span class="line">            dt &#x3D; [_ for cId in p.catIds for _ in self._dts[imgId,cId]]</span><br><span class="line">        if len(gt) &#x3D;&#x3D; 0 and len(dt) &#x3D;&#x3D;0:</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line">        for g in gt:</span><br><span class="line">            if g[&#39;ignore&#39;] or (g[&#39;area&#39;]&lt;aRng[0] or g[&#39;area&#39;]&gt;aRng[1]):</span><br><span class="line">                g[&#39;_ignore&#39;] &#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                g[&#39;_ignore&#39;] &#x3D; 0</span><br><span class="line"></span><br><span class="line">        # sort dt highest score first, sort gt ignore last</span><br><span class="line">        gtind &#x3D; np.argsort([g[&#39;_ignore&#39;] for g in gt], kind&#x3D;&#39;mergesort&#39;)</span><br><span class="line">        gt &#x3D; [gt[i] for i in gtind]</span><br><span class="line">        dtind &#x3D; np.argsort([-d[&#39;score&#39;] for d in dt], kind&#x3D;&#39;mergesort&#39;)</span><br><span class="line">        dt &#x3D; [dt[i] for i in dtind[0:maxDet]]</span><br><span class="line"></span><br><span class="line">        iscrowd &#x3D; [int(o[&#39;iscrowd&#39;]) for o in gt]</span><br><span class="line"></span><br><span class="line">        # load computed ious</span><br><span class="line">        ##两种情况，一张图片中，一种类别的gt存在，则</span><br><span class="line">        ious &#x3D; self.ious[imgId, catId][:, gtind] if len(self.ious[imgId, catId]) &gt; 0 else self.ious[imgId, catId]</span><br><span class="line"></span><br><span class="line">        T &#x3D; len(p.iouThrs)</span><br><span class="line">        G &#x3D; len(gt)</span><br><span class="line">        D &#x3D; len(dt)</span><br><span class="line">        gtm  &#x3D; np.zeros((T,G))  ##存储的是每一个iou阈值、p.maxDet[-1]下的gt能够匹配到的最大iou对应的模型预测框的id，匹配不到的值是0；</span><br><span class="line">        dtm  &#x3D; np.zeros((T,D))   ##存储的是每一个iou阈值下的模型预测框匹配到的gt的id，匹配不到的是0；</span><br><span class="line">        gtIg &#x3D; np.array([g[&#39;_ignore&#39;] for g in gt])</span><br><span class="line">        dtIg &#x3D; np.zeros((T,D))   ##表示每一个阈值下的预测框匹配到的gt是否需要ignore</span><br><span class="line"></span><br><span class="line">        ##dt已经按照置信度排过序，gt已经按照ignore排过位置，非ignore在前，ignore在后面</span><br><span class="line">        ##下面的if里面实现的功能是每一个iou阈值下，遍历预测框(预测框已经按置信度从大到小排序)，一个预测框和gt匹配上，则</span><br><span class="line">        ##另一个预测框不能再通过iou和这个gt进行匹配</span><br><span class="line">        if not len(ious)&#x3D;&#x3D;0:</span><br><span class="line">            for tind, t in enumerate(p.iouThrs):</span><br><span class="line">                for dind, d in enumerate(dt):</span><br><span class="line">                    # information about best match so far (m&#x3D;-1 -&gt; unmatched)</span><br><span class="line">                    iou &#x3D; min([t,1-1e-10])</span><br><span class="line">                    # # 如果m&#x3D; -1 代表这个dt没有得到匹配 m代表dt匹配的最好的gt的索引下标</span><br><span class="line">                    m   &#x3D; -1</span><br><span class="line">                    for gind, g in enumerate(gt):</span><br><span class="line">                        # if this gt already matched, and not a crowd, continue</span><br><span class="line">                        if gtm[tind,gind]&gt;0 and not iscrowd[gind]:</span><br><span class="line">                            continue</span><br><span class="line">                        # if dt matched to reg gt, and on ignore gt, stop</span><br><span class="line">                        if m&gt;-1 and gtIg[m]&#x3D;&#x3D;0 and gtIg[gind]&#x3D;&#x3D;1:</span><br><span class="line">                            break</span><br><span class="line">                        # continue to next gt unless better match made</span><br><span class="line">                        if ious[dind,gind] &lt; iou:</span><br><span class="line">                            continue</span><br><span class="line">                        # if match successful and best so far, store appropriately</span><br><span class="line">                        iou&#x3D;ious[dind,gind]</span><br><span class="line">                        m&#x3D;gind</span><br><span class="line">                    # if match made store id of match for both dt and gt</span><br><span class="line">                    if m &#x3D;&#x3D;-1:</span><br><span class="line">                        continue</span><br><span class="line">                    dtIg[tind,dind] &#x3D; gtIg[m]   ##对应的能匹配上gt的预测框是否ignore</span><br><span class="line">                    dtm[tind,dind]  &#x3D; gt[m][&#39;id&#39;]  ##dt匹配上的gt的id</span><br><span class="line">                    gtm[tind,m]     &#x3D; d[&#39;id&#39;]   ##gt中的框匹配上的预测框的id</span><br><span class="line">        # set unmatched detections outside of area range to ignore</span><br><span class="line">        ##将dtm中没有匹配到gt的预测框，同时预测框的area在指定的aRng范围外，则设置对应的预测框为ignore</span><br><span class="line">        a &#x3D; np.array([d[&#39;area&#39;]&lt;aRng[0] or d[&#39;area&#39;]&gt;aRng[1] for d in dt]).reshape((1, len(dt)))</span><br><span class="line">        dtIg &#x3D; np.logical_or(dtIg, np.logical_and(dtm&#x3D;&#x3D;0, np.repeat(a,T,0)))</span><br><span class="line">        # store results for given image and category</span><br><span class="line">        return &#123;</span><br><span class="line">                &#39;image_id&#39;:     imgId,</span><br><span class="line">                &#39;category_id&#39;:  catId,</span><br><span class="line">                &#39;aRng&#39;:         aRng,   ##aRng范围外的gt和未匹配到gt的预测框但在aRng范围外都是ignore，匹配到gt的预测框在aRng范围外正常计算，不ignore</span><br><span class="line">                &#39;maxDet&#39;:       maxDet,  ##这里是p.maxDets[-1]</span><br><span class="line">                &#39;dtIds&#39;:        [d[&#39;id&#39;] for d in dt], ##已经排过序的预测框id</span><br><span class="line">                &#39;gtIds&#39;:        [g[&#39;id&#39;] for g in gt],</span><br><span class="line">                &#39;dtMatches&#39;:    dtm,  ##(T,D) 其中D是已经按置信度排除的bbox</span><br><span class="line">                &#39;gtMatches&#39;:    gtm,  ##(T,G) G是按照aRng等信息排序的不ignore在前，ignore在后的gt</span><br><span class="line">                &#39;dtScores&#39;:     [d[&#39;score&#39;] for d in dt],   ##已经排过序的score</span><br><span class="line">                &#39;gtIgnore&#39;:     gtIg,  ##G指的是单张图片特定aRng的gt是否ignore信息</span><br><span class="line">                &#39;dtIgnore&#39;:     dtIg, ##(T,D)</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">    def accumulate(self, p &#x3D; None):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        Accumulate per image evaluation results and store the result in self.eval</span><br><span class="line">        :param p: input params for evaluation</span><br><span class="line">        :return: None</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        print(&#39;Accumulating evaluation results...&#39;)</span><br><span class="line">        tic &#x3D; time.time()</span><br><span class="line">        if not self.evalImgs:</span><br><span class="line">            print(&#39;Please run evaluate() first&#39;)</span><br><span class="line">        # allows input customized parameters</span><br><span class="line">        if p is None:</span><br><span class="line">            p &#x3D; self.params</span><br><span class="line">        p.catIds &#x3D; p.catIds if p.useCats &#x3D;&#x3D; 1 else [-1]</span><br><span class="line">        T           &#x3D; len(p.iouThrs)  ##设置的iou阈值的个数</span><br><span class="line">        R           &#x3D; len(p.recThrs)  ##设置的召回的recThrs阈值的个数</span><br><span class="line">        K           &#x3D; len(p.catIds) if p.useCats else 1</span><br><span class="line">        A           &#x3D; len(p.areaRng)</span><br><span class="line">        M           &#x3D; len(p.maxDets)</span><br><span class="line">        G_num       &#x3D; 7800        ##设置的该评估用的数据集的gt总数,可以事先通过cvat查看标注的bbox个数，或者自己评估性的设置一个数</span><br><span class="line">        precision   &#x3D; -np.ones((T,R,K,A,M)) # -1 for the precision of absent categories ##这个是存储不同的rec值下的p值，相当于存储了pr曲线的采样点</span><br><span class="line">        recall      &#x3D; -np.ones((T,K,A,M))</span><br><span class="line">        precision_s &#x3D; -np.ones((T,K,A,M))   ##真实的精确率值</span><br><span class="line">        scores      &#x3D; -np.ones((T,R,K,A,M))</span><br><span class="line">        DTMatch     &#x3D; -np.ones((T,K,A,G_num,M))</span><br><span class="line"></span><br><span class="line">        # create dictionary for future indexing</span><br><span class="line">        _pe &#x3D; self._paramsEval</span><br><span class="line">        catIds &#x3D; _pe.catIds if _pe.useCats else [-1]</span><br><span class="line">        setK &#x3D; set(catIds)</span><br><span class="line">        setA &#x3D; set(map(tuple, _pe.areaRng))</span><br><span class="line">        setM &#x3D; set(_pe.maxDets)</span><br><span class="line">        setI &#x3D; set(_pe.imgIds)</span><br><span class="line">        # get inds to evaluate</span><br><span class="line">        k_list &#x3D; [n for n, k in enumerate(p.catIds)  if k in setK]</span><br><span class="line">        m_list &#x3D; [m for n, m in enumerate(p.maxDets) if m in setM]</span><br><span class="line">        a_list &#x3D; [n for n, a in enumerate(map(lambda x: tuple(x), p.areaRng)) if a in setA]</span><br><span class="line">        i_list &#x3D; [n for n, i in enumerate(p.imgIds)  if i in setI]</span><br><span class="line">        I0 &#x3D; len(_pe.imgIds)</span><br><span class="line">        A0 &#x3D; len(_pe.areaRng)</span><br><span class="line"></span><br><span class="line">        ##根据self.evalImgs的存储形式，遍历时最里层是img_id、次外层是aRng、最外层是类别id</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">            self.evalImgs &#x3D; [evaluateImg(imgId, catId, areaRng, maxDet)</span><br><span class="line">                for catId in catIds</span><br><span class="line">                for areaRng in p.areaRng</span><br><span class="line">                for imgId in p.imgIds</span><br><span class="line">            ]</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        # retrieve E at each category, area range, and max number of detections</span><br><span class="line">        for k, k0 in enumerate(k_list):  ##类别的索引下标遍历</span><br><span class="line">            Nk &#x3D; k0*A0*I0   </span><br><span class="line">            for a, a0 in enumerate(a_list):  ##aRng的遍历</span><br><span class="line">                Na &#x3D; a0*I0</span><br><span class="line">                for m, maxDet in enumerate(m_list):</span><br><span class="line">                    E &#x3D; [self.evalImgs[Nk + Na + i] for i in i_list]</span><br><span class="line">                    E &#x3D; [e for e in E if not e is None]</span><br><span class="line">                    if len(E) &#x3D;&#x3D; 0:</span><br><span class="line">                        continue</span><br><span class="line">                    ##特定类别、特定aRng的所有图片中每一张图片的maxDet个预测框</span><br><span class="line">                    dtScores &#x3D; np.concatenate([e[&#39;dtScores&#39;][0:maxDet] for e in E])  </span><br><span class="line"></span><br><span class="line">                    # different sorting method generates slightly different results.</span><br><span class="line">                    # mergesort is used to be consistent as Matlab implementation.</span><br><span class="line">                    inds &#x3D; np.argsort(-dtScores, kind&#x3D;&#39;mergesort&#39;)</span><br><span class="line">                    ##是将特定类别，特定aRng的所有图片的预测框</span><br><span class="line">                    # (每张图片特定类别、aRng取置信度从大到小的maxDet个框)</span><br><span class="line">                    #的置信度拉成一位数组，然后再次从大到小排列；</span><br><span class="line">                    dtScoresSorted &#x3D; dtScores[inds]</span><br><span class="line">                    ##dtm、dtIg维度是(T,maxDet个数*图片个数)</span><br><span class="line">                    dtm  &#x3D; np.concatenate([e[&#39;dtMatches&#39;][:,0:maxDet] for e in E], axis&#x3D;1)[:,inds]</span><br><span class="line">                    dtIg &#x3D; np.concatenate([e[&#39;dtIgnore&#39;][:,0:maxDet]  for e in E], axis&#x3D;1)[:,inds]</span><br><span class="line">                    gtIg &#x3D; np.concatenate([e[&#39;gtIgnore&#39;] for e in E])  ##gtIg维度是(图片个数，G)</span><br><span class="line">                    npig &#x3D; np.count_nonzero(gtIg&#x3D;&#x3D;0 )   ##gt不ignore的个数</span><br><span class="line">                    if npig &#x3D;&#x3D; 0:</span><br><span class="line">                        continue</span><br><span class="line"></span><br><span class="line">                    ##dtm、dtIg维度是(T,maxDet个数*图片个数)</span><br><span class="line">                    tps &#x3D; np.logical_and(               dtm,  np.logical_not(dtIg) )</span><br><span class="line">                    fps &#x3D; np.logical_and(np.logical_not(dtm), np.logical_not(dtIg) )</span><br><span class="line"></span><br><span class="line">                    ###GT是特定类别、特定aRng、maxDet下所有图片的gt能被预测到的情况</span><br><span class="line">                    #GT &#x3D; [self.evalImgs[Nk + Na + i] for i in i_list]</span><br><span class="line">                    gtmatch_id &#x3D; tps * dtm  ##(T,图片个数*maxDet)</span><br><span class="line">                    indice_gt &#x3D; [np.where(i&gt; 0)for i in gtmatch_id]</span><br><span class="line">                    unique_id &#x3D; np.array([np.unique(i[indice_gt[p]]) for p,i in enumerate(gtmatch_id)])  #(T,d（不同的iou下，maxDet下的预测框能检测到的gt，所以维度d维度不一样）)</span><br><span class="line">                    #gtmatch &#x3D; np.concatenate([e[&#39;gtMatches&#39;] for e in GT], axis&#x3D;1)  ##(T,图片个数*G)</span><br><span class="line">                    #gt_total_num_k_a &#x3D; gtmatch.shape[1]</span><br><span class="line">                    #(T,K,A,G_num,M)</span><br><span class="line">                    for j,id in enumerate(unique_id):</span><br><span class="line">                        gt_total_num_k_a &#x3D; len(id)</span><br><span class="line">                        DTMatch[j,k,a,:gt_total_num_k_a, m] &#x3D; id  ##存储的是预测框能匹配上的gt的id</span><br><span class="line"></span><br><span class="line">                    tp_sum &#x3D; np.cumsum(tps, axis&#x3D;1).astype(dtype&#x3D;np.float)</span><br><span class="line">                    fp_sum &#x3D; np.cumsum(fps, axis&#x3D;1).astype(dtype&#x3D;np.float)</span><br><span class="line"></span><br><span class="line">                    for t, (tp, fp) in enumerate(zip(tp_sum, fp_sum)):</span><br><span class="line">                        tp &#x3D; np.array(tp)</span><br><span class="line">                        fp &#x3D; np.array(fp)</span><br><span class="line">                        nd &#x3D; len(tp)</span><br><span class="line">                        rc &#x3D; tp &#x2F; npig</span><br><span class="line">                        pr &#x3D; tp &#x2F; (fp+tp+np.spacing(1))</span><br><span class="line">                        q  &#x3D; np.zeros((R,))   ##特定召回率下的precision值(pr曲线)</span><br><span class="line">                        ss &#x3D; np.zeros((R,))   ##特定召回率下的对应的bbox的置信度</span><br><span class="line"></span><br><span class="line">                        if nd:</span><br><span class="line">                            recall[t,k,a,m] &#x3D; rc[-1]</span><br><span class="line">                            precision_s[t,k,a,m] &#x3D; pr[-1]</span><br><span class="line">                        else:</span><br><span class="line">                            recall[t,k,a,m] &#x3D; 0</span><br><span class="line">                            precision_s[t,k,a,m] &#x3D; 0</span><br><span class="line"></span><br><span class="line">                        # numpy is slow without cython optimization for accessing elements</span><br><span class="line">                        # use python array gets significant speed improvement</span><br><span class="line">                        pr &#x3D; pr.tolist(); q &#x3D; q.tolist()</span><br><span class="line"></span><br><span class="line">                        for i in range(nd-1, 0, -1):</span><br><span class="line">                            if pr[i] &gt; pr[i-1]:</span><br><span class="line">                                pr[i-1] &#x3D; pr[i]</span><br><span class="line"></span><br><span class="line">                        ##这里调用的np.searchsorted表示p.recThrs中每一个值能插入到rc中的位置索引，其中rc必须是升序</span><br><span class="line">                        inds &#x3D; np.searchsorted(rc, p.recThrs, side&#x3D;&#39;left&#39;)</span><br><span class="line">                        try:</span><br><span class="line">                            for ri, pi in enumerate(inds):</span><br><span class="line">                                q[ri] &#x3D; pr[pi]</span><br><span class="line">                                ss[ri] &#x3D; dtScoresSorted[pi]</span><br><span class="line">                        except:</span><br><span class="line">                            pass</span><br><span class="line">                        precision[t,:,k,a,m] &#x3D; np.array(q)</span><br><span class="line">                        scores[t,:,k,a,m] &#x3D; np.array(ss)</span><br><span class="line">                        </span><br><span class="line">        self.eval &#x3D; &#123;</span><br><span class="line">            &#39;params&#39;: p,</span><br><span class="line">            &#39;counts&#39;: [T, R, K, A, M],</span><br><span class="line">            &#39;date&#39;: datetime.datetime.now().strftime(&#39;%Y-%m-%d %H:%M:%S&#39;),</span><br><span class="line">            &#39;precision&#39;: precision,  ##(T,R,K,A,M)</span><br><span class="line">            &#39;recall&#39;:   recall,    ##(T,K,A,M)</span><br><span class="line">            &#39;precision_s&#39;: precision_s,</span><br><span class="line">            &#39;scores&#39;: scores,  ##(T,R,K,A,M)</span><br><span class="line">            &#39;DTMatch&#39;: DTMatch,</span><br><span class="line">        &#125;</span><br><span class="line">        toc &#x3D; time.time()</span><br><span class="line">        print(&#39;DONE (t&#x3D;&#123;:0.2f&#125;s).&#39;.format( toc-tic))</span><br><span class="line"></span><br><span class="line">    def get_good_predict_data(self):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        该函数主要用于得到评估数据集中gt成功预测的图片，相反可以得到gt预测不好的图片用于离线困难数据挑选；</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        def get_imgid_excellent_predict(save_path, iouThr, areaRng, maxDets, catId):</span><br><span class="line">            </span><br><span class="line">            p &#x3D; self.params</span><br><span class="line">            ##(T,K,A,G_num,M)</span><br><span class="line">            DTMatch &#x3D; self.eval[&#39;DTMatch&#39;]</span><br><span class="line">            aind &#x3D; [i for i, aRng in enumerate(p.areaRngLbl) if aRng &#x3D;&#x3D; areaRng]</span><br><span class="line">            mind &#x3D; [i for i, mDet in enumerate(p.maxDets) if mDet &#x3D;&#x3D; maxDets] </span><br><span class="line">            cind &#x3D;  [i for i, cat in enumerate(p.catIds) if cat in catId]      </span><br><span class="line">            if iouThr is not None:</span><br><span class="line">                t &#x3D; np.where(iouThr &#x3D;&#x3D; p.iouThrs)[0]</span><br><span class="line">                DTMatch &#x3D; DTMatch[t]</span><br><span class="line">            ##应该分类别计算，不然统一取unique的话，一张图中只要有一种类别的一个gt被检测出来，这张图片后续就会认为是预测较好</span><br><span class="line">            ##的样本，但是该图片中同一种类的其他gt或者其他类的gt可能完全没检出，因此需要分类别计算</span><br><span class="line">            ##iou阈值混在一起没问题，或者取特定的iou阈值就可以了</span><br><span class="line">            ##其实也就是将gt的id和这里的np.unique(DTMatch[:,cind,aind,:,mind])取差集就知道漏检情况了，因为id是指的gt的框的索引</span><br><span class="line">            gt_imgid_cat_id &#x3D; copy.deepcopy(self.gt_imgid_cat_id)</span><br><span class="line">            DTMatch &#x3D; DTMatch[:,cind,aind,:,mind]</span><br><span class="line">            #print(DTMatch.shape)</span><br><span class="line">            for i,cat in enumerate(catId):</span><br><span class="line">                DTMatch_catid &#x3D; np.unique(DTMatch[:,i,:])</span><br><span class="line">                DTMatch_catid &#x3D; np.delete(DTMatch_catid,0)</span><br><span class="line">                for j in DTMatch_catid:</span><br><span class="line">                    image_id &#x3D; self.gt_id2img_id[j]</span><br><span class="line">                    gt_imgid_cat_id[image_id][cat].remove(j)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            null_leak_det &#x3D; []   ##存储完全检测出gt bbox的图片id</span><br><span class="line">            for image_id_i in gt_imgid_cat_id.keys():</span><br><span class="line">                num_empty &#x3D; 0</span><br><span class="line">                for catId_i in catId:</span><br><span class="line">                #for catId_i in gt_imgid_cat_id[image_id_i]:</span><br><span class="line">                    if len(gt_imgid_cat_id[image_id_i][catId_i]) &#x3D;&#x3D;0:</span><br><span class="line">                        num_empty +&#x3D; 1</span><br><span class="line">                        #RuntimeError: dictionary changed size during iteration</span><br><span class="line">                        #gt_imgid_cat_id[image_id_i].pop(catId_i)</span><br><span class="line">                #if num_empty &#x3D;&#x3D; len(self.params.catIds):</span><br><span class="line">                if num_empty &#x3D;&#x3D; len(catId):</span><br><span class="line">                    null_leak_det.append(image_id_i)</span><br><span class="line"></span><br><span class="line">            det_gt &#x3D; np.array([ self.cocoGt.loadImgs(ids&#x3D;[i])[0][&#39;file_name&#39;] for i in null_leak_det])</span><br><span class="line">            det_gt &#x3D; np.unique(det_gt)</span><br><span class="line">            np.savetxt(save_path, det_gt, fmt&#x3D;&#39;%s&#39;, delimiter&#x3D;&#39;,&#39;)</span><br><span class="line"></span><br><span class="line">            #json_str &#x3D; json.dumps(gt_imgid_cat_id)</span><br><span class="line">            for img_id_i in null_leak_det:</span><br><span class="line">                gt_imgid_cat_id.pop(img_id_i)</span><br><span class="line"></span><br><span class="line">            #print(&#39;length of gt_imgid_cat_id&#x3D;&#123;&#125;, none_leak_det&#x3D;&#123;&#125;, imgIds&#x3D;&#123;&#125;&#39;.format(len(gt_imgid_cat_id.keys()),len(null_leak_det),len(self.params.imgIds)))</span><br><span class="line">            json_str &#x3D; repr(gt_imgid_cat_id)</span><br><span class="line">            with open(save_path.replace(&#39;.txt&#39;,&#39;.json&#39;).replace(&#39;good&#39;,&#39;leak_det&#39;), &#39;w&#39;) as json_file:</span><br><span class="line">                json_file.write(json_str)</span><br><span class="line">            </span><br><span class="line">            leak_det_gt &#x3D; gt_imgid_cat_id.keys()</span><br><span class="line">            leak_det_gt &#x3D; np.array([ self.cocoGt.loadImgs(ids&#x3D;[i])[0][&#39;file_name&#39;] for i in leak_det_gt])</span><br><span class="line">            leak_det_gt &#x3D; np.unique(leak_det_gt)</span><br><span class="line">            np.savetxt(save_path.replace(&#39;good&#39;,&#39;leak_det&#39;), leak_det_gt, fmt&#x3D;&#39;%s&#39;, delimiter&#x3D;&#39;,&#39;)</span><br><span class="line">            # DTMatch &#x3D; np.unique(DTMatch[:,cind,aind,:,mind])</span><br><span class="line">            # DTMatch &#x3D; np.delete(DTMatch,0)</span><br><span class="line">            # ###检测框对应的gt id和真实的gt的id的差集就是未检测出的gt的框的id</span><br><span class="line">            # #DTMatch.tolist().remove(-1.0)</span><br><span class="line">            # #print(DTMatch)</span><br><span class="line">            # det_gt &#x3D; np.array([ self.cocoGt.loadImgs(ids&#x3D;[self.gt_id2img_id[i]])[0][&#39;file_name&#39;] for i in DTMatch])</span><br><span class="line">            # det_gt &#x3D; np.unique(det_gt)</span><br><span class="line"></span><br><span class="line">            # # with open(save_path,&#39;w+&#39;) as file_object:</span><br><span class="line">            # #     json.dump(DTMatch,file_object)    </span><br><span class="line">            # np.savetxt(save_path, det_gt, fmt&#x3D;&#39;%s&#39;, delimiter&#x3D;&#39;,&#39;)           </span><br><span class="line">            # # f &#x3D; open(save_path,&#39;w+&#39;)</span><br><span class="line">            # # for i in DTMatch:</span><br><span class="line">            # #     f.write(i)</span><br><span class="line">            # #     f.write(&#39;\n&#39;)</span><br><span class="line">            # # f.close()</span><br><span class="line">            #print(&#39;save iou&#x3D;&#123;&#125;| areaRng&#x3D;&#123;&#125;| maxDets&#x3D;&#123;&#125;| catId&#x3D;&#123;&#125; to &#123;&#125;&#39;.format(iouThr, areaRng, maxDets, catId, save_path))</span><br><span class="line"></span><br><span class="line">        save_path &#x3D; r&#39;.&#x2F;good_predict.txt&#39;</span><br><span class="line">        get_imgid_excellent_predict(save_path, iouThr&#x3D;.5, areaRng&#x3D;&#39;all&#39;, maxDets&#x3D;self.params.maxDets[0], catId&#x3D;[self.params.catIds[2]])</span><br><span class="line"></span><br><span class="line">    def summarize(self):</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        Compute and display summary metrics for evaluation results.</span><br><span class="line">        Note this functin can *only* be applied on the default parameter setting</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        def _summarize( ap&#x3D;1, iouThr&#x3D;None, areaRng&#x3D;&#39;all&#39;, maxDets&#x3D;100 , catId&#x3D;self.params.catIds):</span><br><span class="line">            &#39;&#39;&#39;</span><br><span class="line">            precision   &#x3D; -np.ones((T,R,K,A,M)) # -1 for the precision of absent categories ##这个是存储不同的rec值下的p值，相当于存储了pr曲线的采样点</span><br><span class="line">            recall      &#x3D; -np.ones((T,K,A,M))</span><br><span class="line">            precision_s &#x3D; -np.ones((T,K,A,M))   ##真实的精确率值</span><br><span class="line">            &#39;&#39;&#39;</span><br><span class="line">            p &#x3D; self.params</span><br><span class="line">            iStr &#x3D; &#39; &#123;:&lt;18&#125; &#123;&#125; @[ IoU&#x3D;&#123;:&lt;9&#125; | area&#x3D;&#123;:&gt;6s&#125; | maxDets&#x3D;&#123;:&gt;3d&#125; ] &#x3D; &#123;:0.3f&#125;&#39;</span><br><span class="line">            # titleStr &#x3D; &#39;Average Precision&#39; if ap &#x3D;&#x3D; 1 else &#39;Average Recall&#39;</span><br><span class="line">            # typeStr &#x3D; &#39;(AP)&#39; if ap&#x3D;&#x3D;1 else &#39;(AR)&#39;</span><br><span class="line">            #titleStr &#x3D; &#39;Average Precision&#39; if ap &#x3D;&#x3D; 1 else &#39;Average Recall&#39;</span><br><span class="line">            #typeStr &#x3D; &#39;(AP)&#39; if ap&#x3D;&#x3D;1 else &#39;(AR)&#39;</span><br><span class="line">            iouStr &#x3D; &#39;&#123;:0.2f&#125;:&#123;:0.2f&#125;&#39;.format(p.iouThrs[0], p.iouThrs[-1]) \</span><br><span class="line">                if iouThr is None else &#39;&#123;:0.2f&#125;&#39;.format(iouThr)</span><br><span class="line"></span><br><span class="line">            aind &#x3D; [i for i, aRng in enumerate(p.areaRngLbl) if aRng &#x3D;&#x3D; areaRng]</span><br><span class="line">            mind &#x3D; [i for i, mDet in enumerate(p.maxDets) if mDet &#x3D;&#x3D; maxDets]</span><br><span class="line"></span><br><span class="line">            cind &#x3D;  [i for i, cat in enumerate(p.catIds) if cat in catId]</span><br><span class="line"></span><br><span class="line">            if ap &#x3D;&#x3D; 1:</span><br><span class="line">                titleStr &#x3D; &#39;Average P-R curve Area&#39;</span><br><span class="line">                typeStr &#x3D; &#39;(mAP)&#39;</span><br><span class="line">                # dimension of precision: [TxRxKxAxM]</span><br><span class="line">                s &#x3D; self.eval[&#39;precision&#39;]</span><br><span class="line">                # IoU</span><br><span class="line">                if iouThr is not None:</span><br><span class="line">                    t &#x3D; np.where(iouThr &#x3D;&#x3D; p.iouThrs)[0]</span><br><span class="line">                    s &#x3D; s[t]</span><br><span class="line">                #s &#x3D; s[:,:,:,aind,mind]</span><br><span class="line">                s &#x3D; s[:,:,cind,aind,mind]</span><br><span class="line">            elif ap &#x3D;&#x3D; 0:</span><br><span class="line">                titleStr &#x3D; &#39;Average Recall&#39;</span><br><span class="line">                typeStr &#x3D; &#39;(AR)&#39;</span><br><span class="line">                # dimension of recall: [TxKxAxM]</span><br><span class="line">                s &#x3D; self.eval[&#39;recall&#39;]</span><br><span class="line">                if iouThr is not None:</span><br><span class="line">                    t &#x3D; np.where(iouThr &#x3D;&#x3D; p.iouThrs)[0]</span><br><span class="line">                    s &#x3D; s[t]</span><br><span class="line">                #s &#x3D; s[:,:,aind,mind]</span><br><span class="line">                s &#x3D; s[:,cind,aind,mind]</span><br><span class="line"></span><br><span class="line">            else:</span><br><span class="line">                titleStr &#x3D; &#39;Average Precision&#39;</span><br><span class="line">                typeStr &#x3D; &#39;(AP)&#39;</span><br><span class="line">                # dimension of precision: [TxKxAxM]</span><br><span class="line">                s &#x3D; self.eval[&#39;precision_s&#39;]</span><br><span class="line">                # IoU</span><br><span class="line">                if iouThr is not None:</span><br><span class="line">                    t &#x3D; np.where(iouThr &#x3D;&#x3D; p.iouThrs)[0]</span><br><span class="line">                    s &#x3D; s[t]</span><br><span class="line">                #s &#x3D; s[:,:,aind,mind]</span><br><span class="line">                s &#x3D; s[:,cind,aind,mind]</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            if len(s[s&gt;-1])&#x3D;&#x3D;0:</span><br><span class="line">                mean_s &#x3D; -1</span><br><span class="line">            else:</span><br><span class="line">                mean_s &#x3D; np.mean(s[s&gt;-1])</span><br><span class="line">            print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))</span><br><span class="line">            return mean_s</span><br><span class="line"></span><br><span class="line">        def _summarizeDets():</span><br><span class="line">            &#39;&#39;&#39;</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.902</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.985</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.975</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.902</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.687</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.932</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.932</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.932</span><br><span class="line"></span><br><span class="line">            &#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">            &#39;&#39;&#39;</span><br><span class="line">            Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.902</span><br><span class="line">            Average P-R curve Area (mAP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.985</span><br><span class="line">            Average P-R curve Area (mAP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.975</span><br><span class="line">            Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.902</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.687</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.932</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.932</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; -1.000</span><br><span class="line">            Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.932</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.936</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.127</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.013</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.988</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.136</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.981</span><br><span class="line">            Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.135</span><br><span class="line"></span><br><span class="line">            &#39;&#39;&#39;</span><br><span class="line">            #stats &#x3D; np.zeros((12,))</span><br><span class="line">            stats &#x3D; np.zeros((31,))</span><br><span class="line">            stats[0] &#x3D; _summarize(1)</span><br><span class="line">            stats[1] &#x3D; _summarize(1, iouThr&#x3D;.5, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[2] &#x3D; _summarize(1, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[3] &#x3D; _summarize(1, areaRng&#x3D;&#39;small&#39;, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[4] &#x3D; _summarize(1, areaRng&#x3D;&#39;medium&#39;, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[5] &#x3D; _summarize(1, areaRng&#x3D;&#39;large&#39;, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[6] &#x3D; _summarize(0, iouThr&#x3D;.5, maxDets&#x3D;self.params.maxDets[1])</span><br><span class="line">            stats[7] &#x3D; _summarize(0, maxDets&#x3D;self.params.maxDets[1])</span><br><span class="line">            stats[8] &#x3D; _summarize(0, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            #stats[8] &#x3D; _summarize(0, iouThr&#x3D;.5, maxDets&#x3D;self.params.maxDets[0])</span><br><span class="line">            stats[9] &#x3D; _summarize(0, areaRng&#x3D;&#39;small&#39;, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[10] &#x3D; _summarize(0, areaRng&#x3D;&#39;medium&#39;, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[11] &#x3D; _summarize(0, areaRng&#x3D;&#39;large&#39;, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line"></span><br><span class="line">            stats[12] &#x3D; _summarize(2, maxDets&#x3D;self.params.maxDets[0])</span><br><span class="line">            stats[13] &#x3D; _summarize(2, maxDets&#x3D;self.params.maxDets[1])</span><br><span class="line">            stats[14] &#x3D; _summarize(2, maxDets&#x3D;self.params.maxDets[2])</span><br><span class="line">            stats[15] &#x3D; _summarize(2, iouThr&#x3D;.5, maxDets&#x3D;self.params.maxDets[0])</span><br><span class="line">            stats[16] &#x3D; _summarize(2, iouThr&#x3D;.5, maxDets&#x3D;self.params.maxDets[1])</span><br><span class="line">            stats[17] &#x3D; _summarize(2, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[0])</span><br><span class="line">            stats[18] &#x3D; _summarize(2, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            stats[19] &#x3D; _summarize(2, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[0]])</span><br><span class="line">            stats[20] &#x3D; _summarize(2, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[1]])   </span><br><span class="line">            stats[21] &#x3D; _summarize(2, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[2]])  </span><br><span class="line"></span><br><span class="line">            stats[22] &#x3D; _summarize(0, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[0]])</span><br><span class="line">            stats[23] &#x3D; _summarize(0, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[1]])   </span><br><span class="line">            stats[24] &#x3D; _summarize(0, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[2]]) </span><br><span class="line"></span><br><span class="line">            stats[25] &#x3D; _summarize(1, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[0]])</span><br><span class="line">            stats[26] &#x3D; _summarize(1, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[1]])   </span><br><span class="line">            stats[27] &#x3D; _summarize(1, iouThr&#x3D;.75, maxDets&#x3D;self.params.maxDets[1], catId&#x3D;[self.params.catIds[2]]) </span><br><span class="line"></span><br><span class="line">            stats[28] &#x3D; _summarize(1, areaRng&#x3D;&#39;small&#39;, maxDets&#x3D;self.params.maxDets[2], catId&#x3D;[self.params.catIds[2]])</span><br><span class="line">            stats[29] &#x3D; _summarize(1, areaRng&#x3D;&#39;medium&#39;, maxDets&#x3D;self.params.maxDets[2], catId&#x3D;[self.params.catIds[2]])   </span><br><span class="line">            stats[30] &#x3D; _summarize(1, areaRng&#x3D;&#39;large&#39;, maxDets&#x3D;self.params.maxDets[2], catId&#x3D;[self.params.catIds[2]])  </span><br><span class="line"></span><br><span class="line">            # stats &#x3D; np.zeros((2,))</span><br><span class="line">            # stats[0] &#x3D; _summarize(0, iouThr&#x3D;.8, maxDets&#x3D;self.params.maxDets[0])</span><br><span class="line">            # stats[1] &#x3D; _summarize(2, iouThr&#x3D;.8, maxDets&#x3D;self.params.maxDets[0])</span><br><span class="line">            return stats</span><br><span class="line"></span><br><span class="line">        def _summarizeKps():</span><br><span class="line">            stats &#x3D; np.zeros((10,))</span><br><span class="line">            stats[0] &#x3D; _summarize(1, maxDets&#x3D;20)</span><br><span class="line">            stats[1] &#x3D; _summarize(1, maxDets&#x3D;20, iouThr&#x3D;.5)</span><br><span class="line">            stats[2] &#x3D; _summarize(1, maxDets&#x3D;20, iouThr&#x3D;.75)</span><br><span class="line">            stats[3] &#x3D; _summarize(1, maxDets&#x3D;20, areaRng&#x3D;&#39;medium&#39;)</span><br><span class="line">            stats[4] &#x3D; _summarize(1, maxDets&#x3D;20, areaRng&#x3D;&#39;large&#39;)</span><br><span class="line">            stats[5] &#x3D; _summarize(0, maxDets&#x3D;20)</span><br><span class="line">            stats[6] &#x3D; _summarize(0, maxDets&#x3D;20, iouThr&#x3D;.5)</span><br><span class="line">            stats[7] &#x3D; _summarize(0, maxDets&#x3D;20, iouThr&#x3D;.75)</span><br><span class="line">            stats[8] &#x3D; _summarize(0, maxDets&#x3D;20, areaRng&#x3D;&#39;medium&#39;)</span><br><span class="line">            stats[9] &#x3D; _summarize(0, maxDets&#x3D;20, areaRng&#x3D;&#39;large&#39;)</span><br><span class="line">            return stats</span><br><span class="line">        if not self.eval:</span><br><span class="line">            raise Exception(&#39;Please run accumulate() first&#39;)</span><br><span class="line">        iouType &#x3D; self.params.iouType</span><br><span class="line">        if iouType &#x3D;&#x3D; &#39;segm&#39; or iouType &#x3D;&#x3D; &#39;bbox&#39;:</span><br><span class="line">            summarize &#x3D; _summarizeDets</span><br><span class="line">        elif iouType &#x3D;&#x3D; &#39;keypoints&#39;:</span><br><span class="line">            summarize &#x3D; _summarizeKps</span><br><span class="line">        self.stats &#x3D; summarize()</span><br><span class="line"></span><br><span class="line">    def __str__(self):</span><br><span class="line">        self.summarize()</span><br><span class="line"></span><br><span class="line">class Params:</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    Params for coco evaluation api</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    def setDetParams(self):</span><br><span class="line">        self.imgIds &#x3D; []</span><br><span class="line">        self.catIds &#x3D; []</span><br><span class="line">        # np.arange causes trouble.  the data point on arange is slightly larger than the true value</span><br><span class="line">        #array([0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])</span><br><span class="line">        self.iouThrs &#x3D; np.linspace(.5, 0.95, int(np.round((0.95 - .5) &#x2F; .05)) + 1, endpoint&#x3D;True)</span><br><span class="line">        self.recThrs &#x3D; np.linspace(.0, 1.00, int(np.round((1.00 - .0) &#x2F; .01)) + 1, endpoint&#x3D;True)</span><br><span class="line">        self.maxDets &#x3D; [1, 10, 100]</span><br><span class="line">        self.areaRng &#x3D; [[0 ** 2, 1e5 ** 2], [0 ** 2, 32 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]</span><br><span class="line">        self.areaRngLbl &#x3D; [&#39;all&#39;, &#39;small&#39;, &#39;medium&#39;, &#39;large&#39;]</span><br><span class="line">        self.useCats &#x3D; 1</span><br><span class="line"></span><br><span class="line">    def setKpParams(self):</span><br><span class="line">        self.imgIds &#x3D; []</span><br><span class="line">        self.catIds &#x3D; []</span><br><span class="line">        # np.arange causes trouble.  the data point on arange is slightly larger than the true value</span><br><span class="line">        self.iouThrs &#x3D; np.linspace(.5, 0.95, int(np.round((0.95 - .5) &#x2F; .05)) + 1, endpoint&#x3D;True)</span><br><span class="line">        self.recThrs &#x3D; np.linspace(.0, 1.00, int(np.round((1.00 - .0) &#x2F; .01)) + 1, endpoint&#x3D;True)</span><br><span class="line">        self.maxDets &#x3D; [20]</span><br><span class="line">        self.areaRng &#x3D; [[0 ** 2, 1e5 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]</span><br><span class="line">        self.areaRngLbl &#x3D; [&#39;all&#39;, &#39;medium&#39;, &#39;large&#39;]</span><br><span class="line">        self.useCats &#x3D; 1</span><br><span class="line">        self.kpt_oks_sigmas &#x3D; np.array([.26, .25, .25, .35, .35, .79, .79, .72, .72, .62,.62, 1.07, 1.07, .87, .87, .89, .89])&#x2F;10.0</span><br><span class="line"></span><br><span class="line">    def __init__(self, iouType&#x3D;&#39;segm&#39;):</span><br><span class="line">        if iouType &#x3D;&#x3D; &#39;segm&#39; or iouType &#x3D;&#x3D; &#39;bbox&#39;:</span><br><span class="line">            self.setDetParams()</span><br><span class="line">        elif iouType &#x3D;&#x3D; &#39;keypoints&#39;:</span><br><span class="line">            self.setKpParams()</span><br><span class="line">        else:</span><br><span class="line">            raise Exception(&#39;iouType not supported&#39;)</span><br><span class="line">        self.iouType &#x3D; iouType</span><br><span class="line">        # useSegm is deprecated</span><br><span class="line">        self.useSegm &#x3D; None</span><br></pre></td></tr></table></figure>

<h1 id="新增功能"><a href="#新增功能" class="headerlink" title="新增功能"></a>新增功能</h1><p>通过该程序，只需要将任意检测模型的预测输出组织成result_test.json形式，ground truth保存成instances_test.json形式，然后就可以直接调用eval_coco.py进行评估。<br><strong>增加的功能：1、平均精确率的计算；2、可以指定特定CatID进行指标计算；3、保存指定条件下的检测好的样本和错检、漏检样本的名称;</strong><br><strong>具体说明：除了cocoapi本身的AP(cocoapi原始程序的AP其实是mAP，而且只能计算所有类的mAP，没有计算指定类别的mAP功能)和AR计算，对官方cocoapi修改后新增真正的AP(Average precision)计算值(新增功能1)，即修改后的cocoapi输出三种指标，AP平均精确率、AR平均召回率，mAP：pr曲线围成的面积；同时可以输出指定类别CatID(新增功能2)、指定aRng(small、medium、large)、指定maxDets(每张图每个类别的最多检测框个数)、指定IOUthr下的三个指标值；</strong><br><strong>除此之外，为了根据模型预测结果分析得到针对性的模型优化方向，可以根据指定条件（CatID、aRng、maxDets、IOUthr）计算测试集中哪些样本按照指定条件完全检出，并将这些样本名称保存在good_predict.txt文件中，同时将存在漏检或错检的bbox的样本名称和检测结果分别保存在leak_det_predict.txt和leak_det_predict.json中，这样就便于进一步分析模型在哪些测试集样本上表现不佳以及表现不佳的原因，进而可以使用离线数据增强或者其他技术对模型进行针对性优化(新增功能3)！！！</strong><br>三种类别的新版cocoapi调用结果示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">loading annotations into memory...</span><br><span class="line">Done (t&#x3D;0.02s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Loading and preparing results...</span><br><span class="line">DONE (t&#x3D;0.03s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">-----</span><br><span class="line">length of self.params.imgIds: 30    ##总共30个样本</span><br><span class="line">self.params.catIds: [1, 2, 3]       ##总共三种类别</span><br><span class="line">Running per image evaluation...</span><br><span class="line">Evaluate annotation type *bbox*</span><br><span class="line">DONE (t&#x3D;9.42s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t&#x3D;0.08s).</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.508</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.705</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.601</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; 0.298</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; 0.426</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.508</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.564</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.456</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.557</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; 0.345</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; 0.491</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.542</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.421</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.213</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;   all | maxDets&#x3D;100 ] &#x3D; 0.153</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.566</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.50      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.305</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D;  1 ] &#x3D; 0.487</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.254</span><br><span class="line"></span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.131  ##指定IOUthr</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.114</span><br><span class="line"> Average Precision  (AP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.517</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.579</span><br><span class="line"> Average Recall     (AR) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.066</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.951   ##不同类别catID</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.543</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.75      | area&#x3D;   all | maxDets&#x3D; 10 ] &#x3D; 0.058</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; small | maxDets&#x3D;100 ] &#x3D; 0.298   ##不同aRng</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D;medium | maxDets&#x3D;100 ] &#x3D; 0.426</span><br><span class="line"> Average P-R curve Area (mAP) @[ IoU&#x3D;0.50:0.95 | area&#x3D; large | maxDets&#x3D;100 ] &#x3D; 0.303</span><br></pre></td></tr></table></figure>
<p>说明：官方的cocoapi计算的mAP是IOU从0.5到0.95，每隔0.05下计算的所有类别的AP的平均值；<br>具体计算是将模型的预测框先按照每一张图片，每一种类别，按照置信度从大到小得到maxDet个框，然后将测试集中特定类别的所有框按置信度总的排序，继而再对排序后的指定类别的所有框计算tp、fp，然后对所有类别求平均得到mAP(pr曲线的面积)；因此也可以知道pr曲线是成反比例，而且是置信度递减的，置信度越低，recall越高，precision越低。**<em>注意maxDet是指一张图片，一种类别容许的最多模型检测框个数，而不是一张图片，所有类别；如果一张图片单类别检测框不足maxDet，也直接去单类别所有检测框，并不会其他补0等操作**</em></p>]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Assessment Criteria</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
</search>
